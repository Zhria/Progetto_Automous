{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sd2DHK4QYaKH"
   },
   "source": [
    "This module contains the implementation of the PPO algorithm.\n",
    "Ci basiamo sullo pseudocodice presente sul sito di OpenAI per la realizzazione del ppo.\n",
    "https://spinningup.openai.com/en/latest/algorithms/ppo.html#id7\n",
    "Utilizzando un Actor-Critic Method.\n",
    "Ciò suddivide l'implementazione in 8 passi principali:\n",
    "1. Inizializzazione dell'ambiente con policy parameters theta_0, e l'inizial value function parameters w_0.\n",
    "2. Ciclare per k iterazioni\n",
    "3. Raccogliere un set di traiettorie D_k = {τ_i} con una policy pi_k = pi(theta_k)\n",
    "4. Calcolare i reward-to-go R_t\n",
    "5. Calcolare gli advantage estimates A_t basandoci sulla value function V_{w_k}\n",
    "6. Aggiornare la policy massimizzando la PPO-Clip objective (Gradient ascent con adam) . Non scriverò la formula che è complessa\n",
    "7. Aggiornare la value function minimizzando la MSE tra V_{w_k} e R_t (Gradient descent con adam)\n",
    "8. Fine ciclo.\n",
    "\n",
    "Implementiamo tutti i passi nella funzione learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqY5vJI-YaKI",
    "outputId": "1424a1ab-43fe-4315-8154-1bf6372c7ac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on CoLab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 17:26:16.743782: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734193576.760619   56950 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734193576.765936   56950 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-14 17:26:16.781529: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') #ignora warnings\n",
    "#Check if colab is used:\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "  print(\"Not running on CoLab\")\n",
    "if IN_COLAB:\n",
    "  !pip install procgen\n",
    "  !pip install tensorflow_probability\n",
    "  !pip install numpy\n",
    "from rete import ReteNeurale\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import gym\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ohXWluKCYaKJ"
   },
   "outputs": [],
   "source": [
    "class PPO:\n",
    "    def learn(self,env):\n",
    "        #Passo 1 --> Inizializzazione dell'ambiente con policy parameters theta_0, e l'inizial value function parameters w_0.\n",
    "        #Dobbiamo creare una rete neurale per la policy e per la value function.\n",
    "        self.env=env\n",
    "        self.nAzioni=env.action_space.n\n",
    "        self.nStati=env.observation_space.shape\n",
    "        self.listaAzioni=[i for i in range(self.nAzioni)]\n",
    "\n",
    "        print(\"N STATI ENV:\",self.nStati)\n",
    "        print(\"N AZIONI ENV:\",self.nAzioni)\n",
    "        #self.stepsPerEpisode=2048 Per produzione\n",
    "        #self.episodesPerBatch=8 per produzione\n",
    "        #self.nEpoche=200 per produzione.\n",
    "        self.stepsPerEpisode=512\n",
    "        self.episodesPerBatch=1\n",
    "        self.nEpoche=10\n",
    "\n",
    "        self.gamma=0.95\n",
    "        self.epsilon=0.2\n",
    "        self.nUpdatesPerIteration=10\n",
    "        self.cov_mat=tf.linalg.diag(tf.fill([self.nAzioni], 0.5))\n",
    "        self.policyNN=ReteNeurale(self.nStati,self.nAzioni,softmax=True) #Actor\n",
    "        self.valueNN=ReteNeurale(self.nStati,1,False) #Critic\n",
    "        self.policy_optimizer=keras.optimizers.Adam(clipvalue=1.0,learning_rate=1e-3)\n",
    "        self.value_optimizer=keras.optimizers.Adam(learning_rate=0.0005)\n",
    "        self.policyNN.compile(optimizer=self.policy_optimizer)\n",
    "        self.valueNN.compile(optimizer=self.value_optimizer)\n",
    "        #passo 2 ciclare per k iterazioni.\n",
    "        for k in range(self.nEpoche):\n",
    "            states, actions, rewards_to_go, log_probs =self.collect_trajectories()\n",
    "            print(\"Trajectories collected\")\n",
    "           \n",
    "            num_samples=states.shape[0]\n",
    "            batch_size=64 #Faccio calcoli con mini-batches perchè altrimenti vado in Run out of memory fisso.\n",
    "            for i in range(0,num_samples, batch_size):\n",
    "              batch_states=states[i:i+batch_size]\n",
    "              batch_actions=actions[i:i+batch_size]\n",
    "              batch_rewards_to_go=rewards_to_go[i:i+batch_size]\n",
    "              batch_log_probs=log_probs[i:i+batch_size]\n",
    "\n",
    "            \n",
    "              V,latest_log_probs=self.evaluate(batch_states,batch_actions)\n",
    "              advantage=self.calcAdvantages(batch_rewards_to_go,V)\n",
    "              \n",
    "              with tf.GradientTape(persistent=True) as tape:\n",
    "                  _,latest_log_probs=self.evaluate(batch_states,batch_actions)\n",
    "                  surrogated_loss_1, surrogated_loss_2=self.calcSurrogatedLoss(batch_log_probs,latest_log_probs,advantage)\n",
    "                  print(\"Surrogated Loss 1:\", surrogated_loss_1)\n",
    "                  print(\"Surrogated Loss 2:\", surrogated_loss_2)\n",
    "                  policy_loss = -tf.reduce_mean(tf.minimum(surrogated_loss_1, surrogated_loss_2))\n",
    "                  value_loss=tf.reduce_mean(tf.square(batch_rewards_to_go-V)) #MSE tra rewards to go e V\n",
    "                  print(\"Policy Loss:\", policy_loss)\n",
    "                  print(\"Value Loss:\", value_loss)\n",
    "              gradientsPolicy = tape.gradient(policy_loss, self.policyNN.trainable_variables)\n",
    "              self.policy_optimizer.apply_gradients(zip(gradientsPolicy, self.policyNN.trainable_variables))\n",
    "\n",
    "              #gradientsValue = tape.gradient(value_loss, self.valueNN.trainable_variables)\n",
    "              #self.value_optimizer.apply_gradients(zip(gradientsValue, self.valueNN.trainable_variables))\n",
    "              #del tape\n",
    "              print(\"EPOCA:\",k,\" POLICY LOSS:\",policy_loss,\" VALUE LOSS:\",value_loss)\n",
    "\n",
    "\n",
    "    def collect_trajectories(self):\n",
    "        #Passo 3 --> Raccogliere un set di traiettorie D_k = {τ_i} con una policy pi_k = pi(theta_k)\n",
    "        #Dobbiamo raccogliere un set di traiettorie e per fare ciò dobbiamo raccogliere: stati, azioni, rewards, rewards to go, log_prob delle azioni.\n",
    "        batch={\n",
    "            'states':[],\n",
    "            'actions':[],\n",
    "            'rewards':[],\n",
    "            'rewards_to_go':[],\n",
    "            'log_probs':[],\n",
    "        }\n",
    "        stato = self.env.reset()\n",
    "        done = False\n",
    "        #Abbiamo un fisso di 8 episodi per batch con 2048 steps per episodio\n",
    "        for i in range(self.episodesPerBatch):\n",
    "            rewardPerEpisode=[]\n",
    "            print(\"Episode: \",i)\n",
    "            for j in range(self.stepsPerEpisode):\n",
    "                batch['states'].append(stato)\n",
    "                azione,log_prob=self.getAction(stato)\n",
    "                #azione sarà un int, mentre log_prob sarà il logaritmo della probabilità dell'azione\n",
    "                batch['actions'].append(azione)\n",
    "                batch['log_probs'].append(log_prob)\n",
    "                stato, reward, done, info = self.env.step(azione)\n",
    "                #info non usata.\n",
    "                rewardPerEpisode.append(reward)\n",
    "                if done:\n",
    "                    break #Ha raggiunto il termine dell'episodio.\n",
    "            batch['rewards'].append(rewardPerEpisode)\n",
    "        #Calcoliamo i rewards to go --> PASSO 4\n",
    "        batch['rewards_to_go']=self.calcRTG(batch['rewards'])\n",
    "        #return batch states, actions, rewards, rewards to go, log_probs\n",
    "        print(\"BATCH LOG PROBS:\",batch['log_probs'])\n",
    "        batch_statiTensor=tf.convert_to_tensor(batch['states'],dtype=tf.uint8)\n",
    "        batch_azioniTensor=tf.convert_to_tensor(batch['actions'],dtype=tf.int32)\n",
    "        batch_rewards_to_goTensor=tf.convert_to_tensor(batch['rewards_to_go'],dtype=tf.float32)\n",
    "        batch_log_probsTensor=tf.convert_to_tensor(batch['log_probs'],dtype=tf.float32)\n",
    "\n",
    "\n",
    "        return batch_statiTensor, batch_azioniTensor,batch_rewards_to_goTensor,batch_log_probsTensor\n",
    "\n",
    "    def getAction(self,stato):\n",
    "        stato=tf.convert_to_tensor(np.expand_dims(stato, axis=0) ,dtype=tf.float32)# Diventa (1, 64, 64, 3)\n",
    "        azione_pred=self.policyNN(stato)\n",
    "\n",
    "        #Somma probabilità\n",
    "        dist=tfp.distributions.Categorical(probs=tf.squeeze(azione_pred))\n",
    "        azionePresa=dist.sample()\n",
    "        log_prob=dist.log_prob(azionePresa)\n",
    "        return azionePresa, tf.stop_gradient(log_prob)\n",
    "\n",
    "    def calcRTG(self,rewards):\n",
    "        print(\"CALC REWARDS TO GO\")\n",
    "        print(rewards)\n",
    "        #Prendo la formula per calcolare i rewards to go e richiede i cumulative rewards e un fattore di sconto.\n",
    "        rtg=[]\n",
    "        for episode_reward in reversed(rewards):\n",
    "            cumulative_reward=0\n",
    "            for single_reward in reversed(episode_reward):\n",
    "                cumulative_reward=single_reward+cumulative_reward*self.gamma\n",
    "                rtg.append(cumulative_reward)\n",
    "        return tf.convert_to_tensor(rtg,dtype=tf.float32)\n",
    "\n",
    "    def calcAdvantages(self, rtg,values):\n",
    "        advantages=rtg-tf.stop_gradient(values)\n",
    "        return (advantages - tf.reduce_mean(advantages)) / (tf.math.reduce_std(advantages) + 1e-10)\n",
    "\n",
    "    def calcSurrogatedLoss(self,log_probs_old, log_probs_new, advantages):\n",
    "        advantages = tf.stop_gradient(advantages)\n",
    "        print(\"CALC SURROGATED LOSS, ADVANTAGES:\",advantages)\n",
    "        print(\"CALC SURROGATED LOSS, Log probs old:\",log_probs_old)\n",
    "        print(\"CALC SURROGATED LOSS, Log probs new:\",log_probs_new)\n",
    "        policy_ratio = tf.exp(log_probs_old - log_probs_new)\n",
    "        print(\"CALC SURROGATED LOSS, Policy ratio :\",policy_ratio)\n",
    "        surrogated_loss_1 = policy_ratio * advantages\n",
    "        surrogated_loss_2 = tf.clip_by_value(policy_ratio, clip_value_min=1.0-self.epsilon, clip_value_max=1.0+self.epsilon) * advantages\n",
    "        return surrogated_loss_1, surrogated_loss_2\n",
    "\n",
    "    def evaluate(self, batch_states,batch_actions):\n",
    "        batch_states=tf.cast(batch_states, tf.float32)\n",
    "        retVal=self.valueNN(batch_states)\n",
    "        mean=self.policyNN(batch_states)\n",
    "        V= tf.squeeze(retVal)\n",
    "        print(\"V EVALUATE:\",V)\n",
    "        print(\"MEAN EVALUATE:\",mean)\n",
    "        dist=tfp.distributions.Categorical(probs=mean)\n",
    "        log_probs=dist.log_prob(batch_actions)\n",
    "        print(\"LOG PROBS EVALUATE:\",log_probs)\n",
    "        return V, log_probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUvSNGxTYaKK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MRQw7a59YaKK",
    "outputId": "14b44976-8c3c-4514-9d59-8209e0bab64c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N STATI ENV: (64, 64, 3)\n",
      "N AZIONI ENV: 15\n",
      "Episode:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734193581.133296   56950 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2735 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "I0000 00:00:1734193581.854678   56950 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "/home/zakaria/anaconda3/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/zakaria/anaconda3/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALC REWARDS TO GO\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "BATCH LOG PROBS: [<tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0807242393493652>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-3.4989752769470215>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.3625465631484985>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2341182678937912>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-2.015655279159546>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.21838466823101044>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.5662477016448975>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01610848680138588>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2341182678937912>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.4326072931289673>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.3108489513397217>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.21838466823101044>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01610848680138588>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.567518949508667>, <tf.Tensor: shape=(), dtype=float32, numpy=-2.448923110961914>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0807242393493652>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.21838466823101044>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.3108489513397217>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.5662477016448975>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01610848680138588>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0807242393493652>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2341182678937912>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0807242393493652>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.5662477016448975>, <tf.Tensor: shape=(), dtype=float32, numpy=-3.720427989959717>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.21838466823101044>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-3.720427989959717>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.5662477016448975>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01610848680138588>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-4.265058517456055>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.420803427696228>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2341182678937912>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-2.3792901039123535>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.21838466823101044>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-4.474494457244873>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.5662477016448975>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01610848680138588>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2341182678937912>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.21838466823101044>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01610848680138588>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.3625465631484985>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2341182678937912>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.420803427696228>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.5662477016448975>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-2.3792901039123535>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.21838466823101044>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01610848680138588>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0807242393493652>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-2.448923110961914>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2341182678937912>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.3625465631484985>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0807242393493652>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.21838466823101044>, <tf.Tensor: shape=(), dtype=float32, numpy=-2.015655279159546>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.5662477016448975>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01610848680138588>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-3.4989752769470215>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2341182678937912>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.3625465631484985>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-2.3792901039123535>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.21838466823101044>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01610848680138588>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2341182678937912>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.420803427696228>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.3108489513397217>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.21838466823101044>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01610848680138588>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0807242393493652>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.3625465631484985>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2341182678937912>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.3625465631484985>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.3108489513397217>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.21838466823101044>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.5662477016448975>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01610848680138588>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2341182678937912>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.5662477016448975>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.4326072931289673>, <tf.Tensor: shape=(), dtype=float32, numpy=-2.3792901039123535>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.21838466823101044>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.3108489513397217>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.4326072931289673>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-4.141467094421387>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2341182678937912>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0807242393493652>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.4326072931289673>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.6294907331466675>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.4326072931289673>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01610848680138588>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.0807242393493652>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-2.448923110961914>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2341182678937912>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.420803427696228>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.21838466823101044>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.4326072931289673>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01610848680138588>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2341182678937912>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.09055884182453156>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.2957950532436371>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.030805181711912155>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.29294049739837646>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.03446485474705696>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.41540291905403137>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01401581708341837>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.018022703006863594>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.23477531969547272>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0305551216006279>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.3108489513397217>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.21838466823101044>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.14359848201274872>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.31424009799957275>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.0975557491183281>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.28795018792152405>, <tf.Tensor: shape=(), dtype=float32, numpy=-5.142190456390381>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.5662477016448975>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.01610848680138588>, <tf.Tensor: shape=(), dtype=float32, numpy=-6.294052582234144e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-7.819823804311454e-05>, <tf.Tensor: shape=(), dtype=float32, numpy=-0.014234318397939205>]\n",
      "Trajectories collected\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.55363    -2.1602745   5.159771    4.330002    3.6987243   0.09413004\n",
      " -1.5099182  -3.8181849  -1.7793708  -3.8181849  -1.5099182   0.09413004\n",
      "  3.6987243   4.330002    5.159771   -0.8714404  -4.55363    -4.1442957\n",
      " -2.0813823   5.334819    4.6187716   3.7794394   0.11876488 -1.4134083\n",
      " -3.5607285  -1.7755165  -3.5607285  -1.4134083   0.11876488  3.7794394\n",
      "  4.6187716   5.334819   -0.85342455 -4.1442957  -4.55363    -2.1602745\n",
      "  5.159771    4.330002    3.6987243   0.09413004 -1.5099182  -3.8181849\n",
      " -1.7793708  -3.8181849  -1.5099182   0.09413004  3.6987243   4.330002\n",
      "  5.159771   -0.8714404  -4.55363    -4.1442957  -2.0813823   5.334819\n",
      "  4.6187716   3.7794394   0.11876488 -1.4134083  -3.5607285  -1.7755165\n",
      " -3.5607285  -1.4134083   0.11876488  3.7794394 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[3.98704986e-10 5.15887734e-13 7.84679700e-12 1.40213847e-11\n",
      "  2.36923128e-14 9.99921799e-01 4.54043140e-12 2.62462474e-09\n",
      "  1.13052199e-08 9.22810495e-10 2.61453664e-10 7.81610288e-05\n",
      "  1.04549988e-14 5.19437206e-18 3.30190042e-12]\n",
      " [4.31955632e-05 1.24325161e-10 1.42776968e-09 1.01025107e-05\n",
      "  1.18189403e-10 9.85866249e-01 6.22153351e-09 4.67680280e-07\n",
      "  2.59385415e-05 6.95522262e-09 2.57266830e-09 1.40511384e-02\n",
      "  1.19551102e-09 2.95119027e-15 2.87761077e-06]\n",
      " [2.15894545e-07 7.44625819e-11 1.22731870e-12 4.28401341e-04\n",
      "  1.97906771e-15 6.60074711e-01 1.04425857e-10 5.67114466e-10\n",
      "  1.47403480e-04 7.75694886e-09 1.95076996e-10 3.39349240e-01\n",
      "  1.08955955e-10 7.80876233e-17 2.72721259e-08]\n",
      " [1.42758836e-06 1.51817492e-09 7.43843260e-14 7.26718782e-03\n",
      "  6.77190401e-16 9.66123343e-01 1.31909123e-10 8.84178147e-12\n",
      "  2.18000641e-05 8.40755519e-08 7.41592690e-11 2.65861470e-02\n",
      "  3.62312652e-10 4.78903329e-18 3.50539667e-11]\n",
      " [1.20758836e-04 2.58573944e-08 7.26308336e-12 1.22808348e-02\n",
      "  2.00776370e-15 2.41522297e-01 8.20861157e-09 7.62338942e-11\n",
      "  1.12325779e-07 1.18513190e-05 1.52358778e-10 7.46064007e-01\n",
      "  1.19874954e-07 8.63358382e-17 2.51839626e-11]\n",
      " [2.45961792e-06 4.62934358e-09 3.42719099e-13 9.56653894e-05\n",
      "  1.30465383e-15 3.02279536e-02 3.55806122e-08 1.70932268e-10\n",
      "  2.26771881e-08 8.72381315e-06 1.55798915e-10 9.69664931e-01\n",
      "  1.86717671e-07 1.24994455e-16 1.88768411e-11]\n",
      " [5.40670999e-06 1.46660142e-08 2.04989324e-12 3.43454521e-05\n",
      "  7.24347054e-16 7.43937671e-01 2.28153340e-07 5.25853272e-09\n",
      "  6.06324519e-08 1.16851388e-05 5.19087162e-10 2.56010205e-01\n",
      "  3.63969633e-07 5.34788598e-16 2.25905943e-11]\n",
      " [9.24343055e-07 6.93561786e-09 3.57868520e-13 1.82158692e-04\n",
      "  5.00731302e-17 8.63835663e-02 1.05060266e-07 1.31202462e-08\n",
      "  5.10949825e-08 8.90316187e-06 8.15253032e-10 9.13423598e-01\n",
      "  6.96988536e-07 4.82961246e-16 7.54115936e-11]\n",
      " [3.93158825e-06 7.74115438e-09 5.45285995e-12 1.51563669e-04\n",
      "  1.13672065e-15 2.08564207e-01 6.26002247e-07 6.42488658e-08\n",
      "  8.23494020e-08 7.34550304e-06 1.53406432e-09 7.91266084e-01\n",
      "  6.09266272e-06 1.62784232e-15 5.47305368e-10]\n",
      " [9.24343055e-07 6.93561786e-09 3.57868520e-13 1.82158692e-04\n",
      "  5.00731302e-17 8.63835663e-02 1.05060266e-07 1.31202462e-08\n",
      "  5.10949825e-08 8.90316187e-06 8.15253032e-10 9.13423598e-01\n",
      "  6.96988536e-07 4.82961246e-16 7.54115936e-11]\n",
      " [5.40670999e-06 1.46660142e-08 2.04989324e-12 3.43454521e-05\n",
      "  7.24347054e-16 7.43937671e-01 2.28153340e-07 5.25853272e-09\n",
      "  6.06324519e-08 1.16851388e-05 5.19087162e-10 2.56010205e-01\n",
      "  3.63969633e-07 5.34788598e-16 2.25905943e-11]\n",
      " [2.45961792e-06 4.62934358e-09 3.42719099e-13 9.56653894e-05\n",
      "  1.30465383e-15 3.02279536e-02 3.55806122e-08 1.70932268e-10\n",
      "  2.26771881e-08 8.72381315e-06 1.55798915e-10 9.69664931e-01\n",
      "  1.86717671e-07 1.24994455e-16 1.88768411e-11]\n",
      " [1.20758836e-04 2.58573944e-08 7.26308336e-12 1.22808348e-02\n",
      "  2.00776370e-15 2.41522297e-01 8.20861157e-09 7.62338942e-11\n",
      "  1.12325779e-07 1.18513190e-05 1.52358778e-10 7.46064007e-01\n",
      "  1.19874954e-07 8.63358382e-17 2.51839626e-11]\n",
      " [1.42758836e-06 1.51817492e-09 7.43843260e-14 7.26718782e-03\n",
      "  6.77190401e-16 9.66123343e-01 1.31909123e-10 8.84178147e-12\n",
      "  2.18000641e-05 8.40755519e-08 7.41592690e-11 2.65861470e-02\n",
      "  3.62312652e-10 4.78903329e-18 3.50539667e-11]\n",
      " [2.15894545e-07 7.44625819e-11 1.22731870e-12 4.28401341e-04\n",
      "  1.97906771e-15 6.60074711e-01 1.04425857e-10 5.67114466e-10\n",
      "  1.47403480e-04 7.75694886e-09 1.95076996e-10 3.39349240e-01\n",
      "  1.08955955e-10 7.80876233e-17 2.72721259e-08]\n",
      " [2.27926521e-05 8.71647476e-11 2.21022711e-09 4.12823974e-05\n",
      "  7.21758903e-11 9.86081898e-01 2.49717869e-09 2.70364922e-07\n",
      "  2.37401728e-05 1.50447956e-08 5.94459870e-10 1.38252284e-02\n",
      "  1.12875861e-10 6.88991507e-15 4.79588562e-06]\n",
      " [3.98704986e-10 5.15887734e-13 7.84679700e-12 1.40213847e-11\n",
      "  2.36923128e-14 9.99921799e-01 4.54043140e-12 2.62462474e-09\n",
      "  1.13052199e-08 9.22810495e-10 2.61453664e-10 7.81610288e-05\n",
      "  1.04549988e-14 5.19437206e-18 3.30190042e-12]\n",
      " [3.50165758e-10 4.05604939e-13 6.61144750e-12 1.15974053e-11\n",
      "  1.42749785e-14 9.99937057e-01 4.98038156e-12 1.69594105e-09\n",
      "  1.04459765e-08 1.01885145e-09 2.21739058e-10 6.29418137e-05\n",
      "  9.09387871e-15 3.99425665e-18 3.71233252e-12]\n",
      " [4.09045788e-05 1.43230705e-10 1.42192069e-09 9.19605918e-06\n",
      "  9.39159236e-11 9.82138455e-01 5.53043655e-09 3.76981774e-07\n",
      "  2.22772069e-05 9.60740199e-09 2.46685095e-09 1.77859757e-02\n",
      "  9.28101374e-10 2.96679410e-15 2.81825896e-06]\n",
      " [1.22277967e-07 5.22015625e-11 1.15000435e-12 3.06513801e-04\n",
      "  1.53264598e-15 7.90750086e-01 7.42570172e-11 5.17559995e-10\n",
      "  1.17507319e-04 6.76925094e-09 1.28345654e-10 2.08825722e-01\n",
      "  6.99673514e-11 5.84089634e-17 2.23537846e-08]\n",
      " [1.50457959e-06 1.32492362e-09 1.07072832e-13 5.84474532e-03\n",
      "  5.90832586e-16 9.69907939e-01 7.99744715e-11 1.26744509e-11\n",
      "  2.29232592e-05 1.07352903e-07 9.90555693e-11 2.42227931e-02\n",
      "  2.80875795e-10 6.28968575e-18 3.76605171e-11]\n",
      " [1.07550746e-04 2.50056278e-08 6.59700723e-12 1.13960607e-02\n",
      "  1.85355987e-15 2.38687456e-01 7.88460941e-09 7.64035293e-11\n",
      "  1.01012695e-07 1.16055589e-05 1.60902250e-10 7.49797046e-01\n",
      "  1.15478670e-07 8.28895656e-17 2.29687935e-11]\n",
      " [6.58360659e-06 1.41460763e-08 9.36685950e-13 3.08877032e-04\n",
      "  4.15566222e-15 9.26150158e-02 1.00217214e-07 3.92310462e-10\n",
      "  6.71397160e-08 1.57445338e-05 3.91419813e-10 9.07053113e-01\n",
      "  4.97969552e-07 4.40740571e-16 4.12752298e-11]\n",
      " [4.48830770e-06 1.27632669e-08 1.96175650e-12 4.71491148e-05\n",
      "  9.19742997e-16 7.30340660e-01 3.23118996e-07 5.62437696e-09\n",
      "  8.39720968e-08 1.27734029e-05 4.68614592e-10 2.69594133e-01\n",
      "  3.49720125e-07 5.46074200e-16 2.24782797e-11]\n",
      " [1.38642542e-06 8.62026894e-09 6.90266041e-13 5.15033142e-04\n",
      "  1.51517915e-16 1.33228868e-01 1.15160717e-07 2.14263061e-08\n",
      "  7.76675577e-08 1.39990225e-05 1.37393141e-09 8.66239727e-01\n",
      "  7.93026743e-07 1.01985954e-15 1.04828923e-10]\n",
      " [2.87702642e-06 5.99821348e-09 4.50825445e-12 1.37347772e-04\n",
      "  1.06988806e-15 1.96030572e-01 6.69635256e-07 5.12337124e-08\n",
      "  7.44580717e-08 9.36063770e-06 1.57996971e-09 8.03815007e-01\n",
      "  4.03582226e-06 1.32619991e-15 3.64536068e-10]\n",
      " [1.38642542e-06 8.62026894e-09 6.90266041e-13 5.15033142e-04\n",
      "  1.51517915e-16 1.33228868e-01 1.15160717e-07 2.14263061e-08\n",
      "  7.76675577e-08 1.39990225e-05 1.37393141e-09 8.66239727e-01\n",
      "  7.93026743e-07 1.01985954e-15 1.04828923e-10]\n",
      " [4.48830770e-06 1.27632669e-08 1.96175650e-12 4.71491148e-05\n",
      "  9.19742997e-16 7.30340660e-01 3.23118996e-07 5.62437696e-09\n",
      "  8.39720968e-08 1.27734029e-05 4.68614592e-10 2.69594133e-01\n",
      "  3.49720125e-07 5.46074200e-16 2.24782797e-11]\n",
      " [6.58360659e-06 1.41460763e-08 9.36685950e-13 3.08877032e-04\n",
      "  4.15566222e-15 9.26150158e-02 1.00217214e-07 3.92310462e-10\n",
      "  6.71397160e-08 1.57445338e-05 3.91419813e-10 9.07053113e-01\n",
      "  4.97969552e-07 4.40740571e-16 4.12752298e-11]\n",
      " [1.07550746e-04 2.50056278e-08 6.59700723e-12 1.13960607e-02\n",
      "  1.85355987e-15 2.38687456e-01 7.88460941e-09 7.64035293e-11\n",
      "  1.01012695e-07 1.16055589e-05 1.60902250e-10 7.49797046e-01\n",
      "  1.15478670e-07 8.28895656e-17 2.29687935e-11]\n",
      " [1.50457959e-06 1.32492362e-09 1.07072832e-13 5.84474532e-03\n",
      "  5.90832586e-16 9.69907939e-01 7.99744715e-11 1.26744509e-11\n",
      "  2.29232592e-05 1.07352903e-07 9.90555693e-11 2.42227931e-02\n",
      "  2.80875795e-10 6.28968575e-18 3.76605171e-11]\n",
      " [1.22277967e-07 5.22015625e-11 1.15000435e-12 3.06513801e-04\n",
      "  1.53264598e-15 7.90750086e-01 7.42570172e-11 5.17559995e-10\n",
      "  1.17507319e-04 6.76925094e-09 1.28345654e-10 2.08825722e-01\n",
      "  6.99673514e-11 5.84089634e-17 2.23537846e-08]\n",
      " [1.94941513e-05 9.13791681e-11 2.02875361e-09 3.66928762e-05\n",
      "  5.64934072e-11 9.84020472e-01 2.20642460e-09 2.08491088e-07\n",
      "  1.92535081e-05 2.04929300e-08 5.27594635e-10 1.58995669e-02\n",
      "  8.34111044e-11 6.41132240e-15 4.29054262e-06]\n",
      " [3.50165758e-10 4.05604939e-13 6.61144750e-12 1.15974053e-11\n",
      "  1.42749785e-14 9.99937057e-01 4.98038156e-12 1.69594105e-09\n",
      "  1.04459765e-08 1.01885145e-09 2.21739058e-10 6.29418137e-05\n",
      "  9.09387871e-15 3.99425665e-18 3.71233252e-12]\n",
      " [3.98704986e-10 5.15887734e-13 7.84679700e-12 1.40213847e-11\n",
      "  2.36923128e-14 9.99921799e-01 4.54043140e-12 2.62462474e-09\n",
      "  1.13052199e-08 9.22810495e-10 2.61453664e-10 7.81610288e-05\n",
      "  1.04549988e-14 5.19437206e-18 3.30190042e-12]\n",
      " [4.31955632e-05 1.24325161e-10 1.42776968e-09 1.01025107e-05\n",
      "  1.18189403e-10 9.85866249e-01 6.22153351e-09 4.67680280e-07\n",
      "  2.59385415e-05 6.95522262e-09 2.57266830e-09 1.40511384e-02\n",
      "  1.19551102e-09 2.95119027e-15 2.87761077e-06]\n",
      " [2.15894545e-07 7.44625819e-11 1.22731870e-12 4.28401341e-04\n",
      "  1.97906771e-15 6.60074711e-01 1.04425857e-10 5.67114466e-10\n",
      "  1.47403480e-04 7.75694886e-09 1.95076996e-10 3.39349240e-01\n",
      "  1.08955955e-10 7.80876233e-17 2.72721259e-08]\n",
      " [1.42758836e-06 1.51817492e-09 7.43843260e-14 7.26718782e-03\n",
      "  6.77190401e-16 9.66123343e-01 1.31909123e-10 8.84178147e-12\n",
      "  2.18000641e-05 8.40755519e-08 7.41592690e-11 2.65861470e-02\n",
      "  3.62312652e-10 4.78903329e-18 3.50539667e-11]\n",
      " [1.20758836e-04 2.58573944e-08 7.26308336e-12 1.22808348e-02\n",
      "  2.00776370e-15 2.41522297e-01 8.20861157e-09 7.62338942e-11\n",
      "  1.12325779e-07 1.18513190e-05 1.52358778e-10 7.46064007e-01\n",
      "  1.19874954e-07 8.63358382e-17 2.51839626e-11]\n",
      " [2.45961792e-06 4.62934358e-09 3.42719099e-13 9.56653894e-05\n",
      "  1.30465383e-15 3.02279536e-02 3.55806122e-08 1.70932268e-10\n",
      "  2.26771881e-08 8.72381315e-06 1.55798915e-10 9.69664931e-01\n",
      "  1.86717671e-07 1.24994455e-16 1.88768411e-11]\n",
      " [5.40670999e-06 1.46660142e-08 2.04989324e-12 3.43454521e-05\n",
      "  7.24347054e-16 7.43937671e-01 2.28153340e-07 5.25853272e-09\n",
      "  6.06324519e-08 1.16851388e-05 5.19087162e-10 2.56010205e-01\n",
      "  3.63969633e-07 5.34788598e-16 2.25905943e-11]\n",
      " [9.24343055e-07 6.93561786e-09 3.57868520e-13 1.82158692e-04\n",
      "  5.00731302e-17 8.63835663e-02 1.05060266e-07 1.31202462e-08\n",
      "  5.10949825e-08 8.90316187e-06 8.15253032e-10 9.13423598e-01\n",
      "  6.96988536e-07 4.82961246e-16 7.54115936e-11]\n",
      " [3.93158825e-06 7.74115438e-09 5.45285995e-12 1.51563669e-04\n",
      "  1.13672065e-15 2.08564207e-01 6.26002247e-07 6.42488658e-08\n",
      "  8.23494020e-08 7.34550304e-06 1.53406432e-09 7.91266084e-01\n",
      "  6.09266272e-06 1.62784232e-15 5.47305368e-10]\n",
      " [9.24343055e-07 6.93561786e-09 3.57868520e-13 1.82158692e-04\n",
      "  5.00731302e-17 8.63835663e-02 1.05060266e-07 1.31202462e-08\n",
      "  5.10949825e-08 8.90316187e-06 8.15253032e-10 9.13423598e-01\n",
      "  6.96988536e-07 4.82961246e-16 7.54115936e-11]\n",
      " [5.40670999e-06 1.46660142e-08 2.04989324e-12 3.43454521e-05\n",
      "  7.24347054e-16 7.43937671e-01 2.28153340e-07 5.25853272e-09\n",
      "  6.06324519e-08 1.16851388e-05 5.19087162e-10 2.56010205e-01\n",
      "  3.63969633e-07 5.34788598e-16 2.25905943e-11]\n",
      " [2.45961792e-06 4.62934358e-09 3.42719099e-13 9.56653894e-05\n",
      "  1.30465383e-15 3.02279536e-02 3.55806122e-08 1.70932268e-10\n",
      "  2.26771881e-08 8.72381315e-06 1.55798915e-10 9.69664931e-01\n",
      "  1.86717671e-07 1.24994455e-16 1.88768411e-11]\n",
      " [1.20758836e-04 2.58573944e-08 7.26308336e-12 1.22808348e-02\n",
      "  2.00776370e-15 2.41522297e-01 8.20861157e-09 7.62338942e-11\n",
      "  1.12325779e-07 1.18513190e-05 1.52358778e-10 7.46064007e-01\n",
      "  1.19874954e-07 8.63358382e-17 2.51839626e-11]\n",
      " [1.42758836e-06 1.51817492e-09 7.43843260e-14 7.26718782e-03\n",
      "  6.77190401e-16 9.66123343e-01 1.31909123e-10 8.84178147e-12\n",
      "  2.18000641e-05 8.40755519e-08 7.41592690e-11 2.65861470e-02\n",
      "  3.62312652e-10 4.78903329e-18 3.50539667e-11]\n",
      " [2.15894545e-07 7.44625819e-11 1.22731870e-12 4.28401341e-04\n",
      "  1.97906771e-15 6.60074711e-01 1.04425857e-10 5.67114466e-10\n",
      "  1.47403480e-04 7.75694886e-09 1.95076996e-10 3.39349240e-01\n",
      "  1.08955955e-10 7.80876233e-17 2.72721259e-08]\n",
      " [2.27926521e-05 8.71647476e-11 2.21022711e-09 4.12823974e-05\n",
      "  7.21758903e-11 9.86081898e-01 2.49717869e-09 2.70364922e-07\n",
      "  2.37401728e-05 1.50447956e-08 5.94459870e-10 1.38252284e-02\n",
      "  1.12875861e-10 6.88991507e-15 4.79588562e-06]\n",
      " [3.98704986e-10 5.15887734e-13 7.84679700e-12 1.40213847e-11\n",
      "  2.36923128e-14 9.99921799e-01 4.54043140e-12 2.62462474e-09\n",
      "  1.13052199e-08 9.22810495e-10 2.61453664e-10 7.81610288e-05\n",
      "  1.04549988e-14 5.19437206e-18 3.30190042e-12]\n",
      " [3.50165758e-10 4.05604939e-13 6.61144750e-12 1.15974053e-11\n",
      "  1.42749785e-14 9.99937057e-01 4.98038156e-12 1.69594105e-09\n",
      "  1.04459765e-08 1.01885145e-09 2.21739058e-10 6.29418137e-05\n",
      "  9.09387871e-15 3.99425665e-18 3.71233252e-12]\n",
      " [4.09045788e-05 1.43230705e-10 1.42192069e-09 9.19605918e-06\n",
      "  9.39159236e-11 9.82138455e-01 5.53043655e-09 3.76981774e-07\n",
      "  2.22772069e-05 9.60740199e-09 2.46685095e-09 1.77859757e-02\n",
      "  9.28101374e-10 2.96679410e-15 2.81825896e-06]\n",
      " [1.22277967e-07 5.22015625e-11 1.15000435e-12 3.06513801e-04\n",
      "  1.53264598e-15 7.90750086e-01 7.42570172e-11 5.17559995e-10\n",
      "  1.17507319e-04 6.76925094e-09 1.28345654e-10 2.08825722e-01\n",
      "  6.99673514e-11 5.84089634e-17 2.23537846e-08]\n",
      " [1.50457959e-06 1.32492362e-09 1.07072832e-13 5.84474532e-03\n",
      "  5.90832586e-16 9.69907939e-01 7.99744715e-11 1.26744509e-11\n",
      "  2.29232592e-05 1.07352903e-07 9.90555693e-11 2.42227931e-02\n",
      "  2.80875795e-10 6.28968575e-18 3.76605171e-11]\n",
      " [1.07550746e-04 2.50056278e-08 6.59700723e-12 1.13960607e-02\n",
      "  1.85355987e-15 2.38687456e-01 7.88460941e-09 7.64035293e-11\n",
      "  1.01012695e-07 1.16055589e-05 1.60902250e-10 7.49797046e-01\n",
      "  1.15478670e-07 8.28895656e-17 2.29687935e-11]\n",
      " [6.58360659e-06 1.41460763e-08 9.36685950e-13 3.08877032e-04\n",
      "  4.15566222e-15 9.26150158e-02 1.00217214e-07 3.92310462e-10\n",
      "  6.71397160e-08 1.57445338e-05 3.91419813e-10 9.07053113e-01\n",
      "  4.97969552e-07 4.40740571e-16 4.12752298e-11]\n",
      " [4.48830770e-06 1.27632669e-08 1.96175650e-12 4.71491148e-05\n",
      "  9.19742997e-16 7.30340660e-01 3.23118996e-07 5.62437696e-09\n",
      "  8.39720968e-08 1.27734029e-05 4.68614592e-10 2.69594133e-01\n",
      "  3.49720125e-07 5.46074200e-16 2.24782797e-11]\n",
      " [1.38642542e-06 8.62026894e-09 6.90266041e-13 5.15033142e-04\n",
      "  1.51517915e-16 1.33228868e-01 1.15160717e-07 2.14263061e-08\n",
      "  7.76675577e-08 1.39990225e-05 1.37393141e-09 8.66239727e-01\n",
      "  7.93026743e-07 1.01985954e-15 1.04828923e-10]\n",
      " [2.87702642e-06 5.99821348e-09 4.50825445e-12 1.37347772e-04\n",
      "  1.06988806e-15 1.96030572e-01 6.69635256e-07 5.12337124e-08\n",
      "  7.44580717e-08 9.36063770e-06 1.57996971e-09 8.03815007e-01\n",
      "  4.03582226e-06 1.32619991e-15 3.64536068e-10]\n",
      " [1.38642542e-06 8.62026894e-09 6.90266041e-13 5.15033142e-04\n",
      "  1.51517915e-16 1.33228868e-01 1.15160717e-07 2.14263061e-08\n",
      "  7.76675577e-08 1.39990225e-05 1.37393141e-09 8.66239727e-01\n",
      "  7.93026743e-07 1.01985954e-15 1.04828923e-10]\n",
      " [4.48830770e-06 1.27632669e-08 1.96175650e-12 4.71491148e-05\n",
      "  9.19742997e-16 7.30340660e-01 3.23118996e-07 5.62437696e-09\n",
      "  8.39720968e-08 1.27734029e-05 4.68614592e-10 2.69594133e-01\n",
      "  3.49720125e-07 5.46074200e-16 2.24782797e-11]\n",
      " [6.58360659e-06 1.41460763e-08 9.36685950e-13 3.08877032e-04\n",
      "  4.15566222e-15 9.26150158e-02 1.00217214e-07 3.92310462e-10\n",
      "  6.71397160e-08 1.57445338e-05 3.91419813e-10 9.07053113e-01\n",
      "  4.97969552e-07 4.40740571e-16 4.12752298e-11]\n",
      " [1.07550746e-04 2.50056278e-08 6.59700723e-12 1.13960607e-02\n",
      "  1.85355987e-15 2.38687456e-01 7.88460941e-09 7.64035293e-11\n",
      "  1.01012695e-07 1.16055589e-05 1.60902250e-10 7.49797046e-01\n",
      "  1.15478670e-07 8.28895656e-17 2.29687935e-11]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[-7.8198238e-05 -1.4234437e-02 -1.0807254e+00 -3.4463819e-02\n",
      " -2.9294378e-01 -3.4989882e+00 -1.3625380e+00 -9.0555467e-02\n",
      " -2.3412099e-01 -9.0555467e-02 -2.9579806e-01 -3.0804718e-02\n",
      " -2.9294378e-01 -3.4463819e-02 -4.1540229e-01 -1.4015934e-02\n",
      " -7.8198238e-05 -6.2940526e-05 -1.8023055e-02 -2.3477325e-01\n",
      " -3.0554082e-02 -2.8795260e-01 -9.7554341e-02 -3.1424421e-01\n",
      " -2.0156868e+00 -2.1838610e-01 -1.4359362e-01 -3.1424421e-01\n",
      " -9.7554341e-02 -2.8795260e-01 -3.0554082e-02 -1.5662552e+00\n",
      " -1.6108604e-02 -6.2940526e-05 -7.8198238e-05 -1.4234437e-02\n",
      " -4.1540229e-01 -3.4463819e-02 -2.9294378e-01 -3.0804718e-02\n",
      " -2.9579806e-01 -9.0555467e-02 -2.3412099e-01 -9.0555467e-02\n",
      " -2.9579806e-01 -3.0804718e-02 -2.9294378e-01 -3.4463819e-02\n",
      " -4.1540229e-01 -1.4015934e-02 -7.8198238e-05 -6.2940526e-05\n",
      " -1.8023055e-02 -2.3477325e-01 -3.0554082e-02 -1.4326003e+00\n",
      " -9.7554341e-02 -1.3108377e+00 -1.4359362e-01 -2.1838610e-01\n",
      " -1.4359362e-01 -3.1424421e-01 -9.7554341e-02 -2.8795260e-01], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.55363    -2.1602745   5.159771    4.330002    3.6987243   0.09413004\n",
      " -1.5099182  -3.8181849  -1.7793708  -3.8181849  -1.5099182   0.09413004\n",
      "  3.6987243   4.330002    5.159771   -0.8714404  -4.55363    -4.1442957\n",
      " -2.0813823   5.334819    4.6187716   3.7794394   0.11876488 -1.4134083\n",
      " -3.5607285  -1.7755165  -3.5607285  -1.4134083   0.11876488  3.7794394\n",
      "  4.6187716   5.334819   -0.85342455 -4.1442957  -4.55363    -2.1602745\n",
      "  5.159771    4.330002    3.6987243   0.09413004 -1.5099182  -3.8181849\n",
      " -1.7793708  -3.8181849  -1.5099182   0.09413004  3.6987243   4.330002\n",
      "  5.159771   -0.8714404  -4.55363    -4.1442957  -2.0813823   5.334819\n",
      "  4.6187716   3.7794394   0.11876488 -1.4134083  -3.5607285  -1.7755165\n",
      " -3.5607285  -1.4134083   0.11876488  3.7794394 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[3.98704986e-10 5.15887734e-13 7.84679700e-12 1.40213847e-11\n",
      "  2.36923128e-14 9.99921799e-01 4.54043140e-12 2.62462474e-09\n",
      "  1.13052199e-08 9.22810495e-10 2.61453664e-10 7.81610288e-05\n",
      "  1.04549988e-14 5.19437206e-18 3.30190042e-12]\n",
      " [4.31955632e-05 1.24325161e-10 1.42776968e-09 1.01025107e-05\n",
      "  1.18189403e-10 9.85866249e-01 6.22153351e-09 4.67680280e-07\n",
      "  2.59385415e-05 6.95522262e-09 2.57266830e-09 1.40511384e-02\n",
      "  1.19551102e-09 2.95119027e-15 2.87761077e-06]\n",
      " [2.15894545e-07 7.44625819e-11 1.22731870e-12 4.28401341e-04\n",
      "  1.97906771e-15 6.60074711e-01 1.04425857e-10 5.67114466e-10\n",
      "  1.47403480e-04 7.75694886e-09 1.95076996e-10 3.39349240e-01\n",
      "  1.08955955e-10 7.80876233e-17 2.72721259e-08]\n",
      " [1.42758836e-06 1.51817492e-09 7.43843260e-14 7.26718782e-03\n",
      "  6.77190401e-16 9.66123343e-01 1.31909123e-10 8.84178147e-12\n",
      "  2.18000641e-05 8.40755519e-08 7.41592690e-11 2.65861470e-02\n",
      "  3.62312652e-10 4.78903329e-18 3.50539667e-11]\n",
      " [1.20758836e-04 2.58573944e-08 7.26308336e-12 1.22808348e-02\n",
      "  2.00776370e-15 2.41522297e-01 8.20861157e-09 7.62338942e-11\n",
      "  1.12325779e-07 1.18513190e-05 1.52358778e-10 7.46064007e-01\n",
      "  1.19874954e-07 8.63358382e-17 2.51839626e-11]\n",
      " [2.45961792e-06 4.62934358e-09 3.42719099e-13 9.56653894e-05\n",
      "  1.30465383e-15 3.02279536e-02 3.55806122e-08 1.70932268e-10\n",
      "  2.26771881e-08 8.72381315e-06 1.55798915e-10 9.69664931e-01\n",
      "  1.86717671e-07 1.24994455e-16 1.88768411e-11]\n",
      " [5.40670999e-06 1.46660142e-08 2.04989324e-12 3.43454521e-05\n",
      "  7.24347054e-16 7.43937671e-01 2.28153340e-07 5.25853272e-09\n",
      "  6.06324519e-08 1.16851388e-05 5.19087162e-10 2.56010205e-01\n",
      "  3.63969633e-07 5.34788598e-16 2.25905943e-11]\n",
      " [9.24343055e-07 6.93561786e-09 3.57868520e-13 1.82158692e-04\n",
      "  5.00731302e-17 8.63835663e-02 1.05060266e-07 1.31202462e-08\n",
      "  5.10949825e-08 8.90316187e-06 8.15253032e-10 9.13423598e-01\n",
      "  6.96988536e-07 4.82961246e-16 7.54115936e-11]\n",
      " [3.93158825e-06 7.74115438e-09 5.45285995e-12 1.51563669e-04\n",
      "  1.13672065e-15 2.08564207e-01 6.26002247e-07 6.42488658e-08\n",
      "  8.23494020e-08 7.34550304e-06 1.53406432e-09 7.91266084e-01\n",
      "  6.09266272e-06 1.62784232e-15 5.47305368e-10]\n",
      " [9.24343055e-07 6.93561786e-09 3.57868520e-13 1.82158692e-04\n",
      "  5.00731302e-17 8.63835663e-02 1.05060266e-07 1.31202462e-08\n",
      "  5.10949825e-08 8.90316187e-06 8.15253032e-10 9.13423598e-01\n",
      "  6.96988536e-07 4.82961246e-16 7.54115936e-11]\n",
      " [5.40670999e-06 1.46660142e-08 2.04989324e-12 3.43454521e-05\n",
      "  7.24347054e-16 7.43937671e-01 2.28153340e-07 5.25853272e-09\n",
      "  6.06324519e-08 1.16851388e-05 5.19087162e-10 2.56010205e-01\n",
      "  3.63969633e-07 5.34788598e-16 2.25905943e-11]\n",
      " [2.45961792e-06 4.62934358e-09 3.42719099e-13 9.56653894e-05\n",
      "  1.30465383e-15 3.02279536e-02 3.55806122e-08 1.70932268e-10\n",
      "  2.26771881e-08 8.72381315e-06 1.55798915e-10 9.69664931e-01\n",
      "  1.86717671e-07 1.24994455e-16 1.88768411e-11]\n",
      " [1.20758836e-04 2.58573944e-08 7.26308336e-12 1.22808348e-02\n",
      "  2.00776370e-15 2.41522297e-01 8.20861157e-09 7.62338942e-11\n",
      "  1.12325779e-07 1.18513190e-05 1.52358778e-10 7.46064007e-01\n",
      "  1.19874954e-07 8.63358382e-17 2.51839626e-11]\n",
      " [1.42758836e-06 1.51817492e-09 7.43843260e-14 7.26718782e-03\n",
      "  6.77190401e-16 9.66123343e-01 1.31909123e-10 8.84178147e-12\n",
      "  2.18000641e-05 8.40755519e-08 7.41592690e-11 2.65861470e-02\n",
      "  3.62312652e-10 4.78903329e-18 3.50539667e-11]\n",
      " [2.15894545e-07 7.44625819e-11 1.22731870e-12 4.28401341e-04\n",
      "  1.97906771e-15 6.60074711e-01 1.04425857e-10 5.67114466e-10\n",
      "  1.47403480e-04 7.75694886e-09 1.95076996e-10 3.39349240e-01\n",
      "  1.08955955e-10 7.80876233e-17 2.72721259e-08]\n",
      " [2.27926521e-05 8.71647476e-11 2.21022711e-09 4.12823974e-05\n",
      "  7.21758903e-11 9.86081898e-01 2.49717869e-09 2.70364922e-07\n",
      "  2.37401728e-05 1.50447956e-08 5.94459870e-10 1.38252284e-02\n",
      "  1.12875861e-10 6.88991507e-15 4.79588562e-06]\n",
      " [3.98704986e-10 5.15887734e-13 7.84679700e-12 1.40213847e-11\n",
      "  2.36923128e-14 9.99921799e-01 4.54043140e-12 2.62462474e-09\n",
      "  1.13052199e-08 9.22810495e-10 2.61453664e-10 7.81610288e-05\n",
      "  1.04549988e-14 5.19437206e-18 3.30190042e-12]\n",
      " [3.50165758e-10 4.05604939e-13 6.61144750e-12 1.15974053e-11\n",
      "  1.42749785e-14 9.99937057e-01 4.98038156e-12 1.69594105e-09\n",
      "  1.04459765e-08 1.01885145e-09 2.21739058e-10 6.29418137e-05\n",
      "  9.09387871e-15 3.99425665e-18 3.71233252e-12]\n",
      " [4.09045788e-05 1.43230705e-10 1.42192069e-09 9.19605918e-06\n",
      "  9.39159236e-11 9.82138455e-01 5.53043655e-09 3.76981774e-07\n",
      "  2.22772069e-05 9.60740199e-09 2.46685095e-09 1.77859757e-02\n",
      "  9.28101374e-10 2.96679410e-15 2.81825896e-06]\n",
      " [1.22277967e-07 5.22015625e-11 1.15000435e-12 3.06513801e-04\n",
      "  1.53264598e-15 7.90750086e-01 7.42570172e-11 5.17559995e-10\n",
      "  1.17507319e-04 6.76925094e-09 1.28345654e-10 2.08825722e-01\n",
      "  6.99673514e-11 5.84089634e-17 2.23537846e-08]\n",
      " [1.50457959e-06 1.32492362e-09 1.07072832e-13 5.84474532e-03\n",
      "  5.90832586e-16 9.69907939e-01 7.99744715e-11 1.26744509e-11\n",
      "  2.29232592e-05 1.07352903e-07 9.90555693e-11 2.42227931e-02\n",
      "  2.80875795e-10 6.28968575e-18 3.76605171e-11]\n",
      " [1.07550746e-04 2.50056278e-08 6.59700723e-12 1.13960607e-02\n",
      "  1.85355987e-15 2.38687456e-01 7.88460941e-09 7.64035293e-11\n",
      "  1.01012695e-07 1.16055589e-05 1.60902250e-10 7.49797046e-01\n",
      "  1.15478670e-07 8.28895656e-17 2.29687935e-11]\n",
      " [6.58360659e-06 1.41460763e-08 9.36685950e-13 3.08877032e-04\n",
      "  4.15566222e-15 9.26150158e-02 1.00217214e-07 3.92310462e-10\n",
      "  6.71397160e-08 1.57445338e-05 3.91419813e-10 9.07053113e-01\n",
      "  4.97969552e-07 4.40740571e-16 4.12752298e-11]\n",
      " [4.48830770e-06 1.27632669e-08 1.96175650e-12 4.71491148e-05\n",
      "  9.19742997e-16 7.30340660e-01 3.23118996e-07 5.62437696e-09\n",
      "  8.39720968e-08 1.27734029e-05 4.68614592e-10 2.69594133e-01\n",
      "  3.49720125e-07 5.46074200e-16 2.24782797e-11]\n",
      " [1.38642542e-06 8.62026894e-09 6.90266041e-13 5.15033142e-04\n",
      "  1.51517915e-16 1.33228868e-01 1.15160717e-07 2.14263061e-08\n",
      "  7.76675577e-08 1.39990225e-05 1.37393141e-09 8.66239727e-01\n",
      "  7.93026743e-07 1.01985954e-15 1.04828923e-10]\n",
      " [2.87702642e-06 5.99821348e-09 4.50825445e-12 1.37347772e-04\n",
      "  1.06988806e-15 1.96030572e-01 6.69635256e-07 5.12337124e-08\n",
      "  7.44580717e-08 9.36063770e-06 1.57996971e-09 8.03815007e-01\n",
      "  4.03582226e-06 1.32619991e-15 3.64536068e-10]\n",
      " [1.38642542e-06 8.62026894e-09 6.90266041e-13 5.15033142e-04\n",
      "  1.51517915e-16 1.33228868e-01 1.15160717e-07 2.14263061e-08\n",
      "  7.76675577e-08 1.39990225e-05 1.37393141e-09 8.66239727e-01\n",
      "  7.93026743e-07 1.01985954e-15 1.04828923e-10]\n",
      " [4.48830770e-06 1.27632669e-08 1.96175650e-12 4.71491148e-05\n",
      "  9.19742997e-16 7.30340660e-01 3.23118996e-07 5.62437696e-09\n",
      "  8.39720968e-08 1.27734029e-05 4.68614592e-10 2.69594133e-01\n",
      "  3.49720125e-07 5.46074200e-16 2.24782797e-11]\n",
      " [6.58360659e-06 1.41460763e-08 9.36685950e-13 3.08877032e-04\n",
      "  4.15566222e-15 9.26150158e-02 1.00217214e-07 3.92310462e-10\n",
      "  6.71397160e-08 1.57445338e-05 3.91419813e-10 9.07053113e-01\n",
      "  4.97969552e-07 4.40740571e-16 4.12752298e-11]\n",
      " [1.07550746e-04 2.50056278e-08 6.59700723e-12 1.13960607e-02\n",
      "  1.85355987e-15 2.38687456e-01 7.88460941e-09 7.64035293e-11\n",
      "  1.01012695e-07 1.16055589e-05 1.60902250e-10 7.49797046e-01\n",
      "  1.15478670e-07 8.28895656e-17 2.29687935e-11]\n",
      " [1.50457959e-06 1.32492362e-09 1.07072832e-13 5.84474532e-03\n",
      "  5.90832586e-16 9.69907939e-01 7.99744715e-11 1.26744509e-11\n",
      "  2.29232592e-05 1.07352903e-07 9.90555693e-11 2.42227931e-02\n",
      "  2.80875795e-10 6.28968575e-18 3.76605171e-11]\n",
      " [1.22277967e-07 5.22015625e-11 1.15000435e-12 3.06513801e-04\n",
      "  1.53264598e-15 7.90750086e-01 7.42570172e-11 5.17559995e-10\n",
      "  1.17507319e-04 6.76925094e-09 1.28345654e-10 2.08825722e-01\n",
      "  6.99673514e-11 5.84089634e-17 2.23537846e-08]\n",
      " [1.94941513e-05 9.13791681e-11 2.02875361e-09 3.66928762e-05\n",
      "  5.64934072e-11 9.84020472e-01 2.20642460e-09 2.08491088e-07\n",
      "  1.92535081e-05 2.04929300e-08 5.27594635e-10 1.58995669e-02\n",
      "  8.34111044e-11 6.41132240e-15 4.29054262e-06]\n",
      " [3.50165758e-10 4.05604939e-13 6.61144750e-12 1.15974053e-11\n",
      "  1.42749785e-14 9.99937057e-01 4.98038156e-12 1.69594105e-09\n",
      "  1.04459765e-08 1.01885145e-09 2.21739058e-10 6.29418137e-05\n",
      "  9.09387871e-15 3.99425665e-18 3.71233252e-12]\n",
      " [3.98704986e-10 5.15887734e-13 7.84679700e-12 1.40213847e-11\n",
      "  2.36923128e-14 9.99921799e-01 4.54043140e-12 2.62462474e-09\n",
      "  1.13052199e-08 9.22810495e-10 2.61453664e-10 7.81610288e-05\n",
      "  1.04549988e-14 5.19437206e-18 3.30190042e-12]\n",
      " [4.31955632e-05 1.24325161e-10 1.42776968e-09 1.01025107e-05\n",
      "  1.18189403e-10 9.85866249e-01 6.22153351e-09 4.67680280e-07\n",
      "  2.59385415e-05 6.95522262e-09 2.57266830e-09 1.40511384e-02\n",
      "  1.19551102e-09 2.95119027e-15 2.87761077e-06]\n",
      " [2.15894545e-07 7.44625819e-11 1.22731870e-12 4.28401341e-04\n",
      "  1.97906771e-15 6.60074711e-01 1.04425857e-10 5.67114466e-10\n",
      "  1.47403480e-04 7.75694886e-09 1.95076996e-10 3.39349240e-01\n",
      "  1.08955955e-10 7.80876233e-17 2.72721259e-08]\n",
      " [1.42758836e-06 1.51817492e-09 7.43843260e-14 7.26718782e-03\n",
      "  6.77190401e-16 9.66123343e-01 1.31909123e-10 8.84178147e-12\n",
      "  2.18000641e-05 8.40755519e-08 7.41592690e-11 2.65861470e-02\n",
      "  3.62312652e-10 4.78903329e-18 3.50539667e-11]\n",
      " [1.20758836e-04 2.58573944e-08 7.26308336e-12 1.22808348e-02\n",
      "  2.00776370e-15 2.41522297e-01 8.20861157e-09 7.62338942e-11\n",
      "  1.12325779e-07 1.18513190e-05 1.52358778e-10 7.46064007e-01\n",
      "  1.19874954e-07 8.63358382e-17 2.51839626e-11]\n",
      " [2.45961792e-06 4.62934358e-09 3.42719099e-13 9.56653894e-05\n",
      "  1.30465383e-15 3.02279536e-02 3.55806122e-08 1.70932268e-10\n",
      "  2.26771881e-08 8.72381315e-06 1.55798915e-10 9.69664931e-01\n",
      "  1.86717671e-07 1.24994455e-16 1.88768411e-11]\n",
      " [5.40670999e-06 1.46660142e-08 2.04989324e-12 3.43454521e-05\n",
      "  7.24347054e-16 7.43937671e-01 2.28153340e-07 5.25853272e-09\n",
      "  6.06324519e-08 1.16851388e-05 5.19087162e-10 2.56010205e-01\n",
      "  3.63969633e-07 5.34788598e-16 2.25905943e-11]\n",
      " [9.24343055e-07 6.93561786e-09 3.57868520e-13 1.82158692e-04\n",
      "  5.00731302e-17 8.63835663e-02 1.05060266e-07 1.31202462e-08\n",
      "  5.10949825e-08 8.90316187e-06 8.15253032e-10 9.13423598e-01\n",
      "  6.96988536e-07 4.82961246e-16 7.54115936e-11]\n",
      " [3.93158825e-06 7.74115438e-09 5.45285995e-12 1.51563669e-04\n",
      "  1.13672065e-15 2.08564207e-01 6.26002247e-07 6.42488658e-08\n",
      "  8.23494020e-08 7.34550304e-06 1.53406432e-09 7.91266084e-01\n",
      "  6.09266272e-06 1.62784232e-15 5.47305368e-10]\n",
      " [9.24343055e-07 6.93561786e-09 3.57868520e-13 1.82158692e-04\n",
      "  5.00731302e-17 8.63835663e-02 1.05060266e-07 1.31202462e-08\n",
      "  5.10949825e-08 8.90316187e-06 8.15253032e-10 9.13423598e-01\n",
      "  6.96988536e-07 4.82961246e-16 7.54115936e-11]\n",
      " [5.40670999e-06 1.46660142e-08 2.04989324e-12 3.43454521e-05\n",
      "  7.24347054e-16 7.43937671e-01 2.28153340e-07 5.25853272e-09\n",
      "  6.06324519e-08 1.16851388e-05 5.19087162e-10 2.56010205e-01\n",
      "  3.63969633e-07 5.34788598e-16 2.25905943e-11]\n",
      " [2.45961792e-06 4.62934358e-09 3.42719099e-13 9.56653894e-05\n",
      "  1.30465383e-15 3.02279536e-02 3.55806122e-08 1.70932268e-10\n",
      "  2.26771881e-08 8.72381315e-06 1.55798915e-10 9.69664931e-01\n",
      "  1.86717671e-07 1.24994455e-16 1.88768411e-11]\n",
      " [1.20758836e-04 2.58573944e-08 7.26308336e-12 1.22808348e-02\n",
      "  2.00776370e-15 2.41522297e-01 8.20861157e-09 7.62338942e-11\n",
      "  1.12325779e-07 1.18513190e-05 1.52358778e-10 7.46064007e-01\n",
      "  1.19874954e-07 8.63358382e-17 2.51839626e-11]\n",
      " [1.42758836e-06 1.51817492e-09 7.43843260e-14 7.26718782e-03\n",
      "  6.77190401e-16 9.66123343e-01 1.31909123e-10 8.84178147e-12\n",
      "  2.18000641e-05 8.40755519e-08 7.41592690e-11 2.65861470e-02\n",
      "  3.62312652e-10 4.78903329e-18 3.50539667e-11]\n",
      " [2.15894545e-07 7.44625819e-11 1.22731870e-12 4.28401341e-04\n",
      "  1.97906771e-15 6.60074711e-01 1.04425857e-10 5.67114466e-10\n",
      "  1.47403480e-04 7.75694886e-09 1.95076996e-10 3.39349240e-01\n",
      "  1.08955955e-10 7.80876233e-17 2.72721259e-08]\n",
      " [2.27926521e-05 8.71647476e-11 2.21022711e-09 4.12823974e-05\n",
      "  7.21758903e-11 9.86081898e-01 2.49717869e-09 2.70364922e-07\n",
      "  2.37401728e-05 1.50447956e-08 5.94459870e-10 1.38252284e-02\n",
      "  1.12875861e-10 6.88991507e-15 4.79588562e-06]\n",
      " [3.98704986e-10 5.15887734e-13 7.84679700e-12 1.40213847e-11\n",
      "  2.36923128e-14 9.99921799e-01 4.54043140e-12 2.62462474e-09\n",
      "  1.13052199e-08 9.22810495e-10 2.61453664e-10 7.81610288e-05\n",
      "  1.04549988e-14 5.19437206e-18 3.30190042e-12]\n",
      " [3.50165758e-10 4.05604939e-13 6.61144750e-12 1.15974053e-11\n",
      "  1.42749785e-14 9.99937057e-01 4.98038156e-12 1.69594105e-09\n",
      "  1.04459765e-08 1.01885145e-09 2.21739058e-10 6.29418137e-05\n",
      "  9.09387871e-15 3.99425665e-18 3.71233252e-12]\n",
      " [4.09045788e-05 1.43230705e-10 1.42192069e-09 9.19605918e-06\n",
      "  9.39159236e-11 9.82138455e-01 5.53043655e-09 3.76981774e-07\n",
      "  2.22772069e-05 9.60740199e-09 2.46685095e-09 1.77859757e-02\n",
      "  9.28101374e-10 2.96679410e-15 2.81825896e-06]\n",
      " [1.22277967e-07 5.22015625e-11 1.15000435e-12 3.06513801e-04\n",
      "  1.53264598e-15 7.90750086e-01 7.42570172e-11 5.17559995e-10\n",
      "  1.17507319e-04 6.76925094e-09 1.28345654e-10 2.08825722e-01\n",
      "  6.99673514e-11 5.84089634e-17 2.23537846e-08]\n",
      " [1.50457959e-06 1.32492362e-09 1.07072832e-13 5.84474532e-03\n",
      "  5.90832586e-16 9.69907939e-01 7.99744715e-11 1.26744509e-11\n",
      "  2.29232592e-05 1.07352903e-07 9.90555693e-11 2.42227931e-02\n",
      "  2.80875795e-10 6.28968575e-18 3.76605171e-11]\n",
      " [1.07550746e-04 2.50056278e-08 6.59700723e-12 1.13960607e-02\n",
      "  1.85355987e-15 2.38687456e-01 7.88460941e-09 7.64035293e-11\n",
      "  1.01012695e-07 1.16055589e-05 1.60902250e-10 7.49797046e-01\n",
      "  1.15478670e-07 8.28895656e-17 2.29687935e-11]\n",
      " [6.58360659e-06 1.41460763e-08 9.36685950e-13 3.08877032e-04\n",
      "  4.15566222e-15 9.26150158e-02 1.00217214e-07 3.92310462e-10\n",
      "  6.71397160e-08 1.57445338e-05 3.91419813e-10 9.07053113e-01\n",
      "  4.97969552e-07 4.40740571e-16 4.12752298e-11]\n",
      " [4.48830770e-06 1.27632669e-08 1.96175650e-12 4.71491148e-05\n",
      "  9.19742997e-16 7.30340660e-01 3.23118996e-07 5.62437696e-09\n",
      "  8.39720968e-08 1.27734029e-05 4.68614592e-10 2.69594133e-01\n",
      "  3.49720125e-07 5.46074200e-16 2.24782797e-11]\n",
      " [1.38642542e-06 8.62026894e-09 6.90266041e-13 5.15033142e-04\n",
      "  1.51517915e-16 1.33228868e-01 1.15160717e-07 2.14263061e-08\n",
      "  7.76675577e-08 1.39990225e-05 1.37393141e-09 8.66239727e-01\n",
      "  7.93026743e-07 1.01985954e-15 1.04828923e-10]\n",
      " [2.87702642e-06 5.99821348e-09 4.50825445e-12 1.37347772e-04\n",
      "  1.06988806e-15 1.96030572e-01 6.69635256e-07 5.12337124e-08\n",
      "  7.44580717e-08 9.36063770e-06 1.57996971e-09 8.03815007e-01\n",
      "  4.03582226e-06 1.32619991e-15 3.64536068e-10]\n",
      " [1.38642542e-06 8.62026894e-09 6.90266041e-13 5.15033142e-04\n",
      "  1.51517915e-16 1.33228868e-01 1.15160717e-07 2.14263061e-08\n",
      "  7.76675577e-08 1.39990225e-05 1.37393141e-09 8.66239727e-01\n",
      "  7.93026743e-07 1.01985954e-15 1.04828923e-10]\n",
      " [4.48830770e-06 1.27632669e-08 1.96175650e-12 4.71491148e-05\n",
      "  9.19742997e-16 7.30340660e-01 3.23118996e-07 5.62437696e-09\n",
      "  8.39720968e-08 1.27734029e-05 4.68614592e-10 2.69594133e-01\n",
      "  3.49720125e-07 5.46074200e-16 2.24782797e-11]\n",
      " [6.58360659e-06 1.41460763e-08 9.36685950e-13 3.08877032e-04\n",
      "  4.15566222e-15 9.26150158e-02 1.00217214e-07 3.92310462e-10\n",
      "  6.71397160e-08 1.57445338e-05 3.91419813e-10 9.07053113e-01\n",
      "  4.97969552e-07 4.40740571e-16 4.12752298e-11]\n",
      " [1.07550746e-04 2.50056278e-08 6.59700723e-12 1.13960607e-02\n",
      "  1.85355987e-15 2.38687456e-01 7.88460941e-09 7.64035293e-11\n",
      "  1.01012695e-07 1.16055589e-05 1.60902250e-10 7.49797046e-01\n",
      "  1.15478670e-07 8.28895656e-17 2.29687935e-11]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[-7.8198238e-05 -1.4234437e-02 -1.0807254e+00 -3.4463819e-02\n",
      " -2.9294378e-01 -3.4989882e+00 -1.3625380e+00 -9.0555467e-02\n",
      " -2.3412099e-01 -9.0555467e-02 -2.9579806e-01 -3.0804718e-02\n",
      " -2.9294378e-01 -3.4463819e-02 -4.1540229e-01 -1.4015934e-02\n",
      " -7.8198238e-05 -6.2940526e-05 -1.8023055e-02 -2.3477325e-01\n",
      " -3.0554082e-02 -2.8795260e-01 -9.7554341e-02 -3.1424421e-01\n",
      " -2.0156868e+00 -2.1838610e-01 -1.4359362e-01 -3.1424421e-01\n",
      " -9.7554341e-02 -2.8795260e-01 -3.0554082e-02 -1.5662552e+00\n",
      " -1.6108604e-02 -6.2940526e-05 -7.8198238e-05 -1.4234437e-02\n",
      " -4.1540229e-01 -3.4463819e-02 -2.9294378e-01 -3.0804718e-02\n",
      " -2.9579806e-01 -9.0555467e-02 -2.3412099e-01 -9.0555467e-02\n",
      " -2.9579806e-01 -3.0804718e-02 -2.9294378e-01 -3.4463819e-02\n",
      " -4.1540229e-01 -1.4015934e-02 -7.8198238e-05 -6.2940526e-05\n",
      " -1.8023055e-02 -2.3477325e-01 -3.0554082e-02 -1.4326003e+00\n",
      " -9.7554341e-02 -1.3108377e+00 -1.4359362e-01 -2.1838610e-01\n",
      " -1.4359362e-01 -3.1424421e-01 -9.7554341e-02 -2.8795260e-01], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3829131   0.6767528  -1.4830291  -1.2382054  -1.0519468   0.01159002\n",
      "  0.48486498  1.1659198   0.56436706  1.1659198   0.48486498  0.01159002\n",
      " -1.0519468  -1.2382054  -1.4830291   0.2964819   1.3829131   1.262139\n",
      "  0.65347564 -1.534677   -1.323407   -1.0757618   0.0043215   0.4563897\n",
      "  1.0899572   0.56322986  1.0899572   0.4563897   0.0043215  -1.0757618\n",
      " -1.323407   -1.534677    0.2911663   1.262139    1.3829131   0.6767528\n",
      " -1.4830291  -1.2382054  -1.0519468   0.01159002  0.48486498  1.1659198\n",
      "  0.56436706  1.1659198   0.48486498  0.01159002 -1.0519468  -1.2382054\n",
      " -1.4830291   0.2964819   1.3829131   1.262139    0.65347564 -1.534677\n",
      " -1.323407   -1.0757618   0.0043215   0.4563897   1.0899572   0.56322986\n",
      "  1.0899572   0.4563897   0.0043215  -1.0757618 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[-7.8198238e-05 -1.4234318e-02 -1.0807242e+00 -3.4464855e-02\n",
      " -2.9294050e-01 -3.4989753e+00 -1.3625466e+00 -9.0558842e-02\n",
      " -2.3411827e-01 -9.0558842e-02 -2.9579505e-01 -3.0805182e-02\n",
      " -2.9294050e-01 -3.4464855e-02 -4.1540292e-01 -1.4015817e-02\n",
      " -7.8198238e-05 -6.2940526e-05 -1.8022703e-02 -2.3477532e-01\n",
      " -3.0555122e-02 -2.8795019e-01 -9.7555749e-02 -3.1424010e-01\n",
      " -2.0156553e+00 -2.1838467e-01 -1.4359848e-01 -3.1424010e-01\n",
      " -9.7555749e-02 -2.8795019e-01 -3.0555122e-02 -1.5662477e+00\n",
      " -1.6108487e-02 -6.2940526e-05 -7.8198238e-05 -1.4234318e-02\n",
      " -4.1540292e-01 -3.4464855e-02 -2.9294050e-01 -3.0805182e-02\n",
      " -2.9579505e-01 -9.0558842e-02 -2.3411827e-01 -9.0558842e-02\n",
      " -2.9579505e-01 -3.0805182e-02 -2.9294050e-01 -3.4464855e-02\n",
      " -4.1540292e-01 -1.4015817e-02 -7.8198238e-05 -6.2940526e-05\n",
      " -1.8022703e-02 -2.3477532e-01 -3.0555122e-02 -1.4326073e+00\n",
      " -9.7555749e-02 -1.3108490e+00 -1.4359848e-01 -2.1838467e-01\n",
      " -1.4359848e-01 -3.1424010e-01 -9.7555749e-02 -2.8795019e-01], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[-7.8198238e-05 -1.4234437e-02 -1.0807254e+00 -3.4463819e-02\n",
      " -2.9294378e-01 -3.4989882e+00 -1.3625380e+00 -9.0555467e-02\n",
      " -2.3412099e-01 -9.0555467e-02 -2.9579806e-01 -3.0804718e-02\n",
      " -2.9294378e-01 -3.4463819e-02 -4.1540229e-01 -1.4015934e-02\n",
      " -7.8198238e-05 -6.2940526e-05 -1.8023055e-02 -2.3477325e-01\n",
      " -3.0554082e-02 -2.8795260e-01 -9.7554341e-02 -3.1424421e-01\n",
      " -2.0156868e+00 -2.1838610e-01 -1.4359362e-01 -3.1424421e-01\n",
      " -9.7554341e-02 -2.8795260e-01 -3.0554082e-02 -1.5662552e+00\n",
      " -1.6108604e-02 -6.2940526e-05 -7.8198238e-05 -1.4234437e-02\n",
      " -4.1540229e-01 -3.4463819e-02 -2.9294378e-01 -3.0804718e-02\n",
      " -2.9579806e-01 -9.0555467e-02 -2.3412099e-01 -9.0555467e-02\n",
      " -2.9579806e-01 -3.0804718e-02 -2.9294378e-01 -3.4463819e-02\n",
      " -4.1540229e-01 -1.4015934e-02 -7.8198238e-05 -6.2940526e-05\n",
      " -1.8023055e-02 -2.3477325e-01 -3.0554082e-02 -1.4326003e+00\n",
      " -9.7554341e-02 -1.3108377e+00 -1.4359362e-01 -2.1838610e-01\n",
      " -1.4359362e-01 -3.1424421e-01 -9.7554341e-02 -2.8795260e-01], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[1.         1.0000001  1.0000012  0.9999989  1.0000032  1.0000129\n",
      " 0.9999914  0.99999666 1.0000027  0.99999666 1.000003   0.9999995\n",
      " 1.0000032  0.9999989  0.99999934 1.0000001  1.         1.\n",
      " 1.0000004  0.99999785 0.9999989  1.0000025  0.99999857 1.000004\n",
      " 1.0000315  1.0000014  0.9999952  1.000004   0.99999857 1.0000025\n",
      " 0.9999989  1.0000075  1.0000001  1.         1.         1.0000001\n",
      " 0.99999934 0.9999989  1.0000032  0.9999995  1.000003   0.99999666\n",
      " 1.0000027  0.99999666 1.000003   0.9999995  1.0000032  0.9999989\n",
      " 0.99999934 1.0000001  1.         1.         1.0000004  0.99999785\n",
      " 0.9999989  0.999993   0.99999857 0.9999888  0.9999952  1.0000014\n",
      " 0.9999952  1.000004   0.99999857 1.0000025 ], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[ 1.3829131   0.67675287 -1.4830309  -1.2382041  -1.0519501   0.01159017\n",
      "  0.4848608   1.1659158   0.5643686   1.1659158   0.4848664   0.01159001\n",
      " -1.0519501  -1.2382041  -1.4830282   0.29648194  1.3829131   1.262139\n",
      "  0.6534759  -1.5346737  -1.3234056  -1.0757645   0.00432149  0.45639154\n",
      "  1.0899916   0.5632307   1.089952    0.45639154  0.00432149 -1.0757645\n",
      " -1.3234056  -1.5346886   0.29116634  1.262139    1.3829131   0.67675287\n",
      " -1.4830282  -1.2382041  -1.0519501   0.01159001  0.4848664   1.1659158\n",
      "  0.5643686   1.1659158   0.4848664   0.01159001 -1.0519501  -1.2382041\n",
      " -1.4830282   0.29648194  1.3829131   1.262139    0.6534759  -1.5346737\n",
      " -1.3234056  -1.0757543   0.00432149  0.45638457  1.089952    0.5632307\n",
      "  1.089952    0.45639154  0.00432149 -1.0757645 ], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[ 1.3829131   0.67675287 -1.4830309  -1.2382041  -1.0519501   0.01159017\n",
      "  0.4848608   1.1659158   0.5643686   1.1659158   0.4848664   0.01159001\n",
      " -1.0519501  -1.2382041  -1.4830282   0.29648194  1.3829131   1.262139\n",
      "  0.6534759  -1.5346737  -1.3234056  -1.0757645   0.00432149  0.45639154\n",
      "  1.0899916   0.5632307   1.089952    0.45639154  0.00432149 -1.0757645\n",
      " -1.3234056  -1.5346886   0.29116634  1.262139    1.3829131   0.67675287\n",
      " -1.4830282  -1.2382041  -1.0519501   0.01159001  0.4848664   1.1659158\n",
      "  0.5643686   1.1659158   0.4848664   0.01159001 -1.0519501  -1.2382041\n",
      " -1.4830282   0.29648194  1.3829131   1.262139    0.6534759  -1.5346737\n",
      " -1.3234056  -1.0757543   0.00432149  0.45638457  1.089952    0.5632307\n",
      "  1.089952    0.45639154  0.00432149 -1.0757645 ], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(1.8626451e-08, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(11.504828, shape=(), dtype=float32)\n",
      "EPOCA: 0  POLICY LOSS: tf.Tensor(1.8626451e-08, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(11.504828, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[ 4.6187716   5.334819   -0.85342455 -4.1442957  -4.55363    -2.1602745\n",
      "  5.159771    4.330002    3.6987243   0.09413004 -1.5099182  -3.8181849\n",
      " -1.7793708  -3.8181849  -1.5099182   0.09413004  3.6987243   4.330002\n",
      "  5.159771   -0.8714404  -4.55363    -4.1442957  -2.0813823   5.334819\n",
      "  4.6187716   3.7794394   0.11876488 -1.4134083  -3.5607285  -1.7755165\n",
      " -3.5607285  -1.4134083   0.11876488  3.7794394   4.6187716   5.334819\n",
      " -0.85342455 -4.1442957  -4.55363    -2.1602745   5.159771    4.330002\n",
      "  3.6987243   0.09413004 -1.5099182  -3.8181849  -1.7793708  -3.8181849\n",
      " -1.5099182   0.09413004  3.6987243   4.330002    5.159771   -0.8714404\n",
      " -4.55363    -4.1442957  -2.0813823   5.334819    4.6187716   3.7794394\n",
      "  0.11876488 -1.4134083  -3.5607285  -1.7755165 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[5.2478627e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.7058848e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  6.4046362e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.6242438e-38 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7313883e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.6885086e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.1129455e-37 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  7.4775022e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.5645562e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.8165759e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [3.9142470e-41 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.4045979e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [4.4177279e-39 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  8.5774976e-32 1.0000000e+00 2.8025969e-45 0.0000000e+00 0.0000000e+00]\n",
      " [5.7664294e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.8168224e-29 1.0000000e+00 2.7129138e-42 0.0000000e+00 0.0000000e+00]\n",
      " [2.4680313e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.4131354e-28 1.0000000e+00 4.7798291e-42 0.0000000e+00 2.8025969e-45]\n",
      " [1.5240879e-34 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.2209364e-28 1.0000000e+00 6.8816366e-41 0.0000000e+00 4.6242849e-44]\n",
      " [2.4680313e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.4131354e-28 1.0000000e+00 4.7798291e-42 0.0000000e+00 2.8025969e-45]\n",
      " [5.7664294e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.8168224e-29 1.0000000e+00 2.7129138e-42 0.0000000e+00 0.0000000e+00]\n",
      " [4.4177279e-39 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  8.5774976e-32 1.0000000e+00 2.8025969e-45 0.0000000e+00 0.0000000e+00]\n",
      " [3.9142470e-41 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.4045979e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.5645562e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.8165759e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  7.4775022e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7609625e-38 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.6885086e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7313883e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.0282859e-37 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  6.4046362e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.2478627e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.7058848e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [3.6687395e-41 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.2961644e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.1966257e-39 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.2005214e-32 1.0000000e+00 4.2038954e-45 0.0000000e+00 0.0000000e+00]\n",
      " [3.6960444e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.0872633e-29 1.0000000e+00 1.8427075e-42 0.0000000e+00 0.0000000e+00]\n",
      " [1.6966915e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.0236138e-28 1.0000000e+00 3.8787941e-42 0.0000000e+00 4.2038954e-45]\n",
      " [1.8378680e-34 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  3.0517061e-28 1.0000000e+00 6.7000283e-41 0.0000000e+00 5.6051939e-44]\n",
      " [1.6966915e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.0236138e-28 1.0000000e+00 3.8787941e-42 0.0000000e+00 4.2038954e-45]\n",
      " [3.6960444e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.0872633e-29 1.0000000e+00 1.8427075e-42 0.0000000e+00 0.0000000e+00]\n",
      " [5.1966257e-39 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.2005214e-32 1.0000000e+00 4.2038954e-45 0.0000000e+00 0.0000000e+00]\n",
      " [3.6687395e-41 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.2961644e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.2478627e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.7058848e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  6.4046362e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.6242438e-38 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7313883e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.6885086e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.1129455e-37 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  7.4775022e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.5645562e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.8165759e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [3.9142470e-41 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.4045979e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [4.4177279e-39 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  8.5774976e-32 1.0000000e+00 2.8025969e-45 0.0000000e+00 0.0000000e+00]\n",
      " [5.7664294e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.8168224e-29 1.0000000e+00 2.7129138e-42 0.0000000e+00 0.0000000e+00]\n",
      " [2.4680313e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.4131354e-28 1.0000000e+00 4.7798291e-42 0.0000000e+00 2.8025969e-45]\n",
      " [1.5240879e-34 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.2209364e-28 1.0000000e+00 6.8816366e-41 0.0000000e+00 4.6242849e-44]\n",
      " [2.4680313e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.4131354e-28 1.0000000e+00 4.7798291e-42 0.0000000e+00 2.8025969e-45]\n",
      " [5.7664294e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.8168224e-29 1.0000000e+00 2.7129138e-42 0.0000000e+00 0.0000000e+00]\n",
      " [4.4177279e-39 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  8.5774976e-32 1.0000000e+00 2.8025969e-45 0.0000000e+00 0.0000000e+00]\n",
      " [3.9142470e-41 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.4045979e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.5645562e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.8165759e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  7.4775022e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7609625e-38 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.6885086e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7313883e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.0282859e-37 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  6.4046362e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.2478627e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.7058848e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [3.6687395e-41 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.2961644e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.1966257e-39 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.2005214e-32 1.0000000e+00 4.2038954e-45 0.0000000e+00 0.0000000e+00]\n",
      " [3.6960444e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.0872633e-29 1.0000000e+00 1.8427075e-42 0.0000000e+00 0.0000000e+00]\n",
      " [1.6966915e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.0236138e-28 1.0000000e+00 3.8787941e-42 0.0000000e+00 4.2038954e-45]\n",
      " [1.8378680e-34 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  3.0517061e-28 1.0000000e+00 6.7000283e-41 0.0000000e+00 5.6051939e-44]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[-inf -inf -inf -inf -inf -inf -inf -inf  -0.  -0. -inf  -0. -inf -inf\n",
      " -inf  -0.  -0. -inf  -0. -inf -inf -inf -inf -inf -inf  -0.  -0. -inf\n",
      "  -0.  -0.  -0.  -0.  -0.  -0. -inf  -0. -inf -inf -inf -inf  -0. -inf\n",
      "  -0.  -0. -inf  -0.  -0.  -0. -inf  -0.  -0. -inf  -0. -inf -inf -inf\n",
      " -inf  -0.  -0.  -0.  -0. -inf  -0.  -0.], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[ 4.6187716   5.334819   -0.85342455 -4.1442957  -4.55363    -2.1602745\n",
      "  5.159771    4.330002    3.6987243   0.09413004 -1.5099182  -3.8181849\n",
      " -1.7793708  -3.8181849  -1.5099182   0.09413004  3.6987243   4.330002\n",
      "  5.159771   -0.8714404  -4.55363    -4.1442957  -2.0813823   5.334819\n",
      "  4.6187716   3.7794394   0.11876488 -1.4134083  -3.5607285  -1.7755165\n",
      " -3.5607285  -1.4134083   0.11876488  3.7794394   4.6187716   5.334819\n",
      " -0.85342455 -4.1442957  -4.55363    -2.1602745   5.159771    4.330002\n",
      "  3.6987243   0.09413004 -1.5099182  -3.8181849  -1.7793708  -3.8181849\n",
      " -1.5099182   0.09413004  3.6987243   4.330002    5.159771   -0.8714404\n",
      " -4.55363    -4.1442957  -2.0813823   5.334819    4.6187716   3.7794394\n",
      "  0.11876488 -1.4134083  -3.5607285  -1.7755165 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[5.2478627e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.7058848e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  6.4046362e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.6242438e-38 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7313883e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.6885086e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.1129455e-37 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  7.4775022e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.5645562e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.8165759e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [3.9142470e-41 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.4045979e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [4.4177279e-39 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  8.5774976e-32 1.0000000e+00 2.8025969e-45 0.0000000e+00 0.0000000e+00]\n",
      " [5.7664294e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.8168224e-29 1.0000000e+00 2.7129138e-42 0.0000000e+00 0.0000000e+00]\n",
      " [2.4680313e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.4131354e-28 1.0000000e+00 4.7798291e-42 0.0000000e+00 2.8025969e-45]\n",
      " [1.5240879e-34 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.2209364e-28 1.0000000e+00 6.8816366e-41 0.0000000e+00 4.6242849e-44]\n",
      " [2.4680313e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.4131354e-28 1.0000000e+00 4.7798291e-42 0.0000000e+00 2.8025969e-45]\n",
      " [5.7664294e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.8168224e-29 1.0000000e+00 2.7129138e-42 0.0000000e+00 0.0000000e+00]\n",
      " [4.4177279e-39 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  8.5774976e-32 1.0000000e+00 2.8025969e-45 0.0000000e+00 0.0000000e+00]\n",
      " [3.9142470e-41 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.4045979e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.5645562e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.8165759e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  7.4775022e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7609625e-38 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.6885086e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7313883e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.0282859e-37 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  6.4046362e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.2478627e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.7058848e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [3.6687395e-41 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.2961644e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.1966257e-39 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.2005214e-32 1.0000000e+00 4.2038954e-45 0.0000000e+00 0.0000000e+00]\n",
      " [3.6960444e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.0872633e-29 1.0000000e+00 1.8427075e-42 0.0000000e+00 0.0000000e+00]\n",
      " [1.6966915e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.0236138e-28 1.0000000e+00 3.8787941e-42 0.0000000e+00 4.2038954e-45]\n",
      " [1.8378680e-34 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  3.0517061e-28 1.0000000e+00 6.7000283e-41 0.0000000e+00 5.6051939e-44]\n",
      " [1.6966915e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.0236138e-28 1.0000000e+00 3.8787941e-42 0.0000000e+00 4.2038954e-45]\n",
      " [3.6960444e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.0872633e-29 1.0000000e+00 1.8427075e-42 0.0000000e+00 0.0000000e+00]\n",
      " [5.1966257e-39 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.2005214e-32 1.0000000e+00 4.2038954e-45 0.0000000e+00 0.0000000e+00]\n",
      " [3.6687395e-41 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.2961644e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.2478627e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.7058848e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  6.4046362e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.6242438e-38 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7313883e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.6885086e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.1129455e-37 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  7.4775022e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.5645562e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.8165759e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [3.9142470e-41 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.4045979e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [4.4177279e-39 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  8.5774976e-32 1.0000000e+00 2.8025969e-45 0.0000000e+00 0.0000000e+00]\n",
      " [5.7664294e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.8168224e-29 1.0000000e+00 2.7129138e-42 0.0000000e+00 0.0000000e+00]\n",
      " [2.4680313e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.4131354e-28 1.0000000e+00 4.7798291e-42 0.0000000e+00 2.8025969e-45]\n",
      " [1.5240879e-34 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.2209364e-28 1.0000000e+00 6.8816366e-41 0.0000000e+00 4.6242849e-44]\n",
      " [2.4680313e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.4131354e-28 1.0000000e+00 4.7798291e-42 0.0000000e+00 2.8025969e-45]\n",
      " [5.7664294e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.8168224e-29 1.0000000e+00 2.7129138e-42 0.0000000e+00 0.0000000e+00]\n",
      " [4.4177279e-39 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  8.5774976e-32 1.0000000e+00 2.8025969e-45 0.0000000e+00 0.0000000e+00]\n",
      " [3.9142470e-41 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.4045979e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.5645562e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.8165759e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  7.4775022e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7609625e-38 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.6885086e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7313883e-40 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.0282859e-37 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  6.4046362e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.2478627e-42 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.7058848e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [3.6687395e-41 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  2.2961644e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [5.1966257e-39 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  9.2005214e-32 1.0000000e+00 4.2038954e-45 0.0000000e+00 0.0000000e+00]\n",
      " [3.6960444e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  5.0872633e-29 1.0000000e+00 1.8427075e-42 0.0000000e+00 0.0000000e+00]\n",
      " [1.6966915e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.0236138e-28 1.0000000e+00 3.8787941e-42 0.0000000e+00 4.2038954e-45]\n",
      " [1.8378680e-34 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  3.0517061e-28 1.0000000e+00 6.7000283e-41 0.0000000e+00 5.6051939e-44]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[-inf -inf -inf -inf -inf -inf -inf -inf  -0.  -0. -inf  -0. -inf -inf\n",
      " -inf  -0.  -0. -inf  -0. -inf -inf -inf -inf -inf -inf  -0.  -0. -inf\n",
      "  -0.  -0.  -0.  -0.  -0.  -0. -inf  -0. -inf -inf -inf -inf  -0. -inf\n",
      "  -0.  -0. -inf  -0.  -0.  -0. -inf  -0.  -0. -inf  -0. -inf -inf -inf\n",
      " -inf  -0.  -0.  -0.  -0. -inf  -0.  -0.], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-1.2645513  -1.4707583   0.31132987  1.2590338   1.3769137   0.6876761\n",
      " -1.420348   -1.1813915  -0.9995963   0.03845346  0.5003867   1.1651205\n",
      "  0.57798356  1.1651205   0.5003867   0.03845346 -0.9995963  -1.1813915\n",
      " -1.420348    0.31651807  1.3769137   1.2590338   0.66495675 -1.4707583\n",
      " -1.2645513  -1.0228406   0.03135913  0.47259378  1.0909784   0.5768736\n",
      "  1.0909784   0.47259378  0.03135913 -1.0228406  -1.2645513  -1.4707583\n",
      "  0.31132987  1.2590338   1.3769137   0.6876761  -1.420348   -1.1813915\n",
      " -0.9995963   0.03845346  0.5003867   1.1651205   0.57798356  1.1651205\n",
      "  0.5003867   0.03845346 -0.9995963  -1.1813915  -1.420348    0.31651807\n",
      "  1.3769137   1.2590338   0.66495675 -1.4707583  -1.2645513  -1.0228406\n",
      "  0.03135913  0.47259378  1.0909784   0.5768736 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[-3.0555122e-02 -2.3477532e-01 -1.6108487e-02 -6.2940526e-05\n",
      " -7.8198238e-05 -1.4234318e-02 -4.1540292e-01 -3.4464855e-02\n",
      " -2.9294050e-01 -3.0805182e-02 -2.9579505e-01 -9.0558842e-02\n",
      " -1.5675189e+00 -2.4489231e+00 -2.9579505e-01 -3.0805182e-02\n",
      " -2.9294050e-01 -3.4464855e-02 -1.0807242e+00 -1.4015817e-02\n",
      " -7.8198238e-05 -6.2940526e-05 -1.8022703e-02 -2.3477532e-01\n",
      " -3.0555122e-02 -2.8795019e-01 -9.7555749e-02 -3.1424010e-01\n",
      " -1.4359848e-01 -2.1838467e-01 -1.4359848e-01 -1.3108490e+00\n",
      " -9.7555749e-02 -2.8795019e-01 -3.0555122e-02 -1.5662477e+00\n",
      " -1.6108487e-02 -6.2940526e-05 -7.8198238e-05 -1.4234318e-02\n",
      " -1.0807242e+00 -3.4464855e-02 -2.9294050e-01 -3.0805182e-02\n",
      " -2.9579505e-01 -9.0558842e-02 -2.3411827e-01 -9.0558842e-02\n",
      " -2.9579505e-01 -3.0805182e-02 -2.9294050e-01 -3.4464855e-02\n",
      " -1.0807242e+00 -1.4015817e-02 -7.8198238e-05 -6.2940526e-05\n",
      " -1.8022703e-02 -1.5662477e+00 -3.7204280e+00 -2.8795019e-01\n",
      " -9.7555749e-02 -3.1424010e-01 -1.4359848e-01 -2.1838467e-01], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[-inf -inf -inf -inf -inf -inf -inf -inf  -0.  -0. -inf  -0. -inf -inf\n",
      " -inf  -0.  -0. -inf  -0. -inf -inf -inf -inf -inf -inf  -0.  -0. -inf\n",
      "  -0.  -0.  -0.  -0.  -0.  -0. -inf  -0. -inf -inf -inf -inf  -0. -inf\n",
      "  -0.  -0. -inf  -0.  -0.  -0. -inf  -0.  -0. -inf  -0. -inf -inf -inf\n",
      " -inf  -0.  -0.  -0.  -0. -inf  -0.  -0.], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[       inf        inf        inf        inf        inf        inf\n",
      "        inf        inf 0.7460665  0.96966445        inf 0.91342056\n",
      "        inf        inf        inf 0.96966445 0.7460665         inf\n",
      " 0.33934966        inf        inf        inf        inf        inf\n",
      "        inf 0.74979895 0.90705174        inf 0.8662355  0.8038162\n",
      " 0.8662355  0.2695911  0.90705174 0.74979895        inf 0.2088273\n",
      "        inf        inf        inf        inf 0.33934966        inf\n",
      " 0.7460665  0.96966445        inf 0.91342056 0.7912682  0.91342056\n",
      "        inf 0.96966445 0.7460665         inf 0.33934966        inf\n",
      "        inf        inf        inf 0.2088273  0.0242236  0.74979895\n",
      " 0.90705174        inf 0.8662355  0.8038162 ], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[       -inf        -inf         inf         inf         inf         inf\n",
      "        -inf        -inf -0.7457653   0.03728695         inf  1.064245\n",
      "         inf         inf         inf  0.03728695 -0.7457653         -inf\n",
      " -0.48199463         inf         inf         inf         inf        -inf\n",
      "        -inf -0.7669248   0.02844435         inf  0.9450442   0.46370035\n",
      "  0.9450442   0.12740707  0.02844435 -0.7669248         -inf -0.30713448\n",
      "         inf         inf         inf         inf -0.48199463        -inf\n",
      " -0.7457653   0.03728695         inf  1.064245    0.45734003  1.064245\n",
      "         inf  0.03728695 -0.7457653         -inf -0.48199463         inf\n",
      "         inf         inf         inf -0.30713448 -0.03063198 -0.7669248\n",
      "  0.02844435         inf  0.9450442   0.46370035], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[-1.5174617  -1.7649101   0.37359586  1.5108407   1.6522964   0.82521135\n",
      " -1.7044177  -1.4176698  -0.7996771   0.03728695  0.6004641   1.064245\n",
      "  0.69358027  1.3981446   0.6004641   0.03728695 -0.7996771  -1.4176698\n",
      " -1.1362785   0.3798217   1.6522964   1.5108407   0.7979481  -1.7649101\n",
      " -1.5174617  -0.81827253  0.02844435  0.56711257  0.9450442   0.46370035\n",
      "  0.9450442   0.37807503  0.02844435 -0.81827253 -1.5174617  -1.1766067\n",
      "  0.37359586  1.5108407   1.6522964   0.82521135 -1.1362785  -1.4176698\n",
      " -0.7996771   0.03728695  0.6004641   1.064245    0.46238685  1.064245\n",
      "  0.6004641   0.03728695 -0.7996771  -1.4176698  -1.1362785   0.3798217\n",
      "  1.6522964   1.5108407   0.7979481  -1.1766067  -1.011641   -0.81827253\n",
      "  0.02844435  0.56711257  0.9450442   0.46370035], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(inf, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(12.10986, shape=(), dtype=float32)\n",
      "EPOCA: 0  POLICY LOSS: tf.Tensor(inf, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(12.10986, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-3.5607285  -1.4134083   0.11876488  3.7794394   4.6187716   5.334819\n",
      " -0.85342455 -4.1442957  -4.55363    -2.1602745   5.159771    4.330002\n",
      "  3.6987243   0.09413004 -1.5099182  -3.8181849  -1.7793708  -3.8181849\n",
      " -1.5099182   0.09413004  3.6987243   4.330002    5.159771   -0.8714404\n",
      " -4.55363    -4.1442957  -2.0813823   5.334819    4.6187716   3.7794394\n",
      "  0.11876488 -1.4134083  -3.5607285  -1.7755165  -3.5607285  -1.4134083\n",
      "  0.11876488  3.7794394   4.6187716   5.334819   -0.85342455 -4.1442957\n",
      " -4.55363    -2.1602745   5.159771    4.330002    3.6987243   0.09413004\n",
      " -1.5099182  -3.8181849  -1.7793708  -3.8181849  -1.5099182   0.09413004\n",
      "  3.6987243   4.330002    5.159771   -0.8714404  -4.55363    -4.1442957\n",
      " -2.0813823   5.334819    4.6187716   3.7794394 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-3.5607285  -1.4134083   0.11876488  3.7794394   4.6187716   5.334819\n",
      " -0.85342455 -4.1442957  -4.55363    -2.1602745   5.159771    4.330002\n",
      "  3.6987243   0.09413004 -1.5099182  -3.8181849  -1.7793708  -3.8181849\n",
      " -1.5099182   0.09413004  3.6987243   4.330002    5.159771   -0.8714404\n",
      " -4.55363    -4.1442957  -2.0813823   5.334819    4.6187716   3.7794394\n",
      "  0.11876488 -1.4134083  -3.5607285  -1.7755165  -3.5607285  -1.4134083\n",
      "  0.11876488  3.7794394   4.6187716   5.334819   -0.85342455 -4.1442957\n",
      " -4.55363    -2.1602745   5.159771    4.330002    3.6987243   0.09413004\n",
      " -1.5099182  -3.8181849  -1.7793708  -3.8181849  -1.5099182   0.09413004\n",
      "  3.6987243   4.330002    5.159771   -0.8714404  -4.55363    -4.1442957\n",
      " -2.0813823   5.334819    4.6187716   3.7794394 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.1101484   0.49499187  0.05606049 -0.9926363  -1.2330852  -1.4382157\n",
      "  0.33456978  1.2773266   1.3945912   0.7089514  -1.3880687  -1.1503594\n",
      " -0.9695133   0.06311779  0.5226397   1.1839036   0.59983146  1.1839036\n",
      "  0.5226397   0.06311779 -0.9695133  -1.1503594  -1.3880687   0.3397309\n",
      "  1.3945912   1.2773266   0.68635064 -1.4382157  -1.2330852  -0.9926363\n",
      "  0.05606049  0.49499187  1.1101484   0.59872735  1.1101484   0.49499187\n",
      "  0.05606049 -0.9926363  -1.2330852  -1.4382157   0.33456978  1.2773266\n",
      "  1.3945912   0.7089514  -1.3880687  -1.1503594  -0.9695133   0.06311779\n",
      "  0.5226397   1.1839036   0.59983146  1.1839036   0.5226397   0.06311779\n",
      " -0.9695133  -1.1503594  -1.3880687   0.3397309   1.3945912   1.2773266\n",
      "  0.68635064 -1.4382157  -1.2330852  -0.9926363 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[-1.4359848e-01 -3.1424010e-01 -9.7555749e-02 -2.8795019e-01\n",
      " -3.7204280e+00 -1.5662477e+00 -1.6108487e-02 -6.2940526e-05\n",
      " -7.8198238e-05 -4.2650585e+00 -4.1540292e-01 -3.4464855e-02\n",
      " -1.4208034e+00 -3.0805182e-02 -2.9579505e-01 -9.0558842e-02\n",
      " -2.3411827e-01 -9.0558842e-02 -2.9579505e-01 -3.0805182e-02\n",
      " -2.9294050e-01 -3.4464855e-02 -4.1540292e-01 -1.4015817e-02\n",
      " -7.8198238e-05 -6.2940526e-05 -1.8022703e-02 -2.3477532e-01\n",
      " -3.0555122e-02 -2.8795019e-01 -2.3792901e+00 -3.1424010e-01\n",
      " -1.4359848e-01 -2.1838467e-01 -1.4359848e-01 -3.1424010e-01\n",
      " -9.7555749e-02 -4.4744945e+00 -3.0555122e-02 -1.5662477e+00\n",
      " -1.6108487e-02 -6.2940526e-05 -7.8198238e-05 -1.4234318e-02\n",
      " -4.1540292e-01 -3.4464855e-02 -2.9294050e-01 -3.0805182e-02\n",
      " -2.9579505e-01 -9.0558842e-02 -2.3411827e-01 -9.0558842e-02\n",
      " -2.9579505e-01 -3.0805182e-02 -2.9294050e-01 -3.4464855e-02\n",
      " -4.1540292e-01 -1.4015817e-02 -7.8198238e-05 -6.2940526e-05\n",
      " -1.8022703e-02 -2.3477532e-01 -3.0555122e-02 -2.8795019e-01], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(12.283793, shape=(), dtype=float32)\n",
      "EPOCA: 0  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(12.283793, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[ 0.11876488 -1.4134083  -3.5607285  -1.7755165  -3.5607285  -1.4134083\n",
      "  0.11876488  3.7794394   4.6187716   5.334819   -0.85342455 -4.1442957\n",
      " -4.55363    -2.1602745   5.159771    4.330002    3.6987243   0.09413004\n",
      " -1.5099182  -3.8181849  -1.7793708  -3.8181849  -1.5099182   0.09413004\n",
      "  3.6987243   4.330002    5.159771   -0.8714404  -4.55363    -4.1442957\n",
      " -2.0813823   5.334819    4.6187716   3.7794394   0.11876488 -1.4134083\n",
      " -3.5607285  -1.7755165  -3.5607285  -1.4134083   0.11876488  3.7794394\n",
      "  4.6187716   5.334819   -0.85342455 -4.1442957  -4.55363    -2.1602745\n",
      "  5.159771    4.330002    3.6987243   0.09413004 -1.5099182  -3.8181849\n",
      " -1.7793708  -3.8181849  -1.5099182   0.09413004  3.6987243   4.330002\n",
      "  5.159771   -0.8714404  -4.55363    -4.1442957 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[ 0.11876488 -1.4134083  -3.5607285  -1.7755165  -3.5607285  -1.4134083\n",
      "  0.11876488  3.7794394   4.6187716   5.334819   -0.85342455 -4.1442957\n",
      " -4.55363    -2.1602745   5.159771    4.330002    3.6987243   0.09413004\n",
      " -1.5099182  -3.8181849  -1.7793708  -3.8181849  -1.5099182   0.09413004\n",
      "  3.6987243   4.330002    5.159771   -0.8714404  -4.55363    -4.1442957\n",
      " -2.0813823   5.334819    4.6187716   3.7794394   0.11876488 -1.4134083\n",
      " -3.5607285  -1.7755165  -3.5607285  -1.4134083   0.11876488  3.7794394\n",
      "  4.6187716   5.334819   -0.85342455 -4.1442957  -4.55363    -2.1602745\n",
      "  5.159771    4.330002    3.6987243   0.09413004 -1.5099182  -3.8181849\n",
      " -1.7793708  -3.8181849  -1.5099182   0.09413004  3.6987243   4.330002\n",
      "  5.159771   -0.8714404  -4.55363    -4.1442957 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.02654038  0.4254131   1.0588199   0.53222615  1.0588199   0.4254131\n",
      " -0.02654038 -1.1063496  -1.353932   -1.5651484   0.26023164  1.2309579\n",
      "  1.3517015   0.6457203  -1.5135136  -1.268752   -1.0825406  -0.01927371\n",
      "  0.45388117  1.1347632   0.5333631   1.1347632   0.45388117 -0.01927371\n",
      " -1.0825406  -1.268752   -1.5135136   0.26554587  1.3517015   1.2309579\n",
      "  0.62244904 -1.5651484  -1.353932   -1.1063496  -0.02654038  0.4254131\n",
      "  1.0588199   0.53222615  1.0588199   0.4254131  -0.02654038 -1.1063496\n",
      " -1.353932   -1.5651484   0.26023164  1.2309579   1.3517015   0.6457203\n",
      " -1.5135136  -1.268752   -1.0825406  -0.01927371  0.45388117  1.1347632\n",
      "  0.5333631   1.1347632   0.45388117 -0.01927371 -1.0825406  -1.268752\n",
      " -1.5135136   0.26554587  1.3517015   1.2309579 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[-9.7555749e-02 -3.1424010e-01 -1.4359848e-01 -2.1838467e-01\n",
      " -1.4359848e-01 -3.1424010e-01 -9.7555749e-02 -2.8795019e-01\n",
      " -3.0555122e-02 -2.3477532e-01 -1.6108487e-02 -6.2940526e-05\n",
      " -7.8198238e-05 -1.4234318e-02 -4.1540292e-01 -3.4464855e-02\n",
      " -2.9294050e-01 -3.0805182e-02 -1.3625466e+00 -9.0558842e-02\n",
      " -2.3411827e-01 -9.0558842e-02 -2.9579505e-01 -3.0805182e-02\n",
      " -1.4208034e+00 -3.4464855e-02 -4.1540292e-01 -1.4015817e-02\n",
      " -7.8198238e-05 -6.2940526e-05 -1.8022703e-02 -1.5662477e+00\n",
      " -3.0555122e-02 -2.8795019e-01 -2.3792901e+00 -3.1424010e-01\n",
      " -1.4359848e-01 -2.1838467e-01 -1.4359848e-01 -3.1424010e-01\n",
      " -9.7555749e-02 -2.8795019e-01 -3.0555122e-02 -2.3477532e-01\n",
      " -1.6108487e-02 -6.2940526e-05 -7.8198238e-05 -1.4234318e-02\n",
      " -1.0807242e+00 -3.4464855e-02 -2.9294050e-01 -3.0805182e-02\n",
      " -2.9579505e-01 -2.4489231e+00 -2.3411827e-01 -9.0558842e-02\n",
      " -1.3625466e+00 -3.0805182e-02 -2.9294050e-01 -3.4464855e-02\n",
      " -1.0807242e+00 -1.4015817e-02 -7.8198238e-05 -6.2940526e-05], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(11.4936905, shape=(), dtype=float32)\n",
      "EPOCA: 0  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(11.4936905, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-2.0813823   5.334819    4.6187716   3.7794394   0.11876488 -1.4134083\n",
      " -3.5607285  -1.7755165  -3.5607285  -1.4134083   0.11876488  3.7794394\n",
      "  4.6187716   5.334819   -0.85342455 -4.1442957  -4.55363    -2.1602745\n",
      "  5.159771    4.330002    3.6987243   0.09413004 -1.5099182  -3.8181849\n",
      " -1.7793708  -3.8181849  -1.5099182   0.09413004  3.6987243   4.330002\n",
      "  5.159771   -0.8714404  -4.55363    -4.1442957  -2.0813823   5.334819\n",
      "  4.6187716   3.7794394   0.11876488 -1.4134083  -3.5607285  -1.7755165\n",
      " -3.5607285  -1.4134083   0.11876488  3.7794394   4.6187716   5.334819\n",
      " -0.85342455 -4.1442957  -4.55363    -2.1602745   5.159771    4.330002\n",
      "  3.6987243   0.09413004 -1.5099182  -3.8181849  -1.7793708  -3.8181849\n",
      " -1.5099182   0.09413004  3.6987243   4.330002  ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-2.0813823   5.334819    4.6187716   3.7794394   0.11876488 -1.4134083\n",
      " -3.5607285  -1.7755165  -3.5607285  -1.4134083   0.11876488  3.7794394\n",
      "  4.6187716   5.334819   -0.85342455 -4.1442957  -4.55363    -2.1602745\n",
      "  5.159771    4.330002    3.6987243   0.09413004 -1.5099182  -3.8181849\n",
      " -1.7793708  -3.8181849  -1.5099182   0.09413004  3.6987243   4.330002\n",
      "  5.159771   -0.8714404  -4.55363    -4.1442957  -2.0813823   5.334819\n",
      "  4.6187716   3.7794394   0.11876488 -1.4134083  -3.5607285  -1.7755165\n",
      " -3.5607285  -1.4134083   0.11876488  3.7794394   4.6187716   5.334819\n",
      " -0.85342455 -4.1442957  -4.55363    -2.1602745   5.159771    4.330002\n",
      "  3.6987243   0.09413004 -1.5099182  -3.8181849  -1.7793708  -3.8181849\n",
      " -1.5099182   0.09413004  3.6987243   4.330002  ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 0.6973476  -1.4929899  -1.2815089  -1.0336164   0.04754523  0.5000648\n",
      "  1.1342651   0.6070117   1.1342651   0.5000648   0.04754523 -1.0336164\n",
      " -1.2815089  -1.4929899   0.33467644  1.3066187   1.4275135   0.720648\n",
      " -1.4412904  -1.1962223  -1.0097777   0.05482101  0.52856857  1.2103034\n",
      "  0.60815     1.2103034   0.52856857  0.05482101 -1.0097777  -1.1962223\n",
      " -1.4412904   0.33999735  1.4275135   1.3066187   0.6973476  -1.4929899\n",
      " -1.2815089  -1.0336164   0.04754523  0.5000648   1.1342651   0.6070117\n",
      "  1.1342651   0.5000648   0.04754523 -1.0336164  -1.2815089  -1.4929899\n",
      "  0.33467644  1.3066187   1.4275135   0.720648   -1.4412904  -1.1962223\n",
      " -1.0097777   0.05482101  0.52856857  1.2103034   0.60815     1.2103034\n",
      "  0.52856857  0.05482101 -1.0097777  -1.1962223 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[-1.8022703e-02 -2.3477532e-01 -3.0555122e-02 -2.8795019e-01\n",
      " -9.7555749e-02 -3.1424010e-01 -1.4359848e-01 -2.1838467e-01\n",
      " -2.0156553e+00 -3.1424010e-01 -9.7555749e-02 -2.8795019e-01\n",
      " -3.0555122e-02 -1.5662477e+00 -1.6108487e-02 -6.2940526e-05\n",
      " -7.8198238e-05 -1.4234318e-02 -4.1540292e-01 -3.4464855e-02\n",
      " -2.9294050e-01 -3.4989753e+00 -2.9579505e-01 -9.0558842e-02\n",
      " -2.3411827e-01 -9.0558842e-02 -1.3625466e+00 -3.0805182e-02\n",
      " -2.9294050e-01 -3.4464855e-02 -4.1540292e-01 -1.4015817e-02\n",
      " -7.8198238e-05 -6.2940526e-05 -1.8022703e-02 -2.3477532e-01\n",
      " -3.0555122e-02 -2.8795019e-01 -2.3792901e+00 -3.1424010e-01\n",
      " -1.4359848e-01 -2.1838467e-01 -1.4359848e-01 -3.1424010e-01\n",
      " -9.7555749e-02 -2.8795019e-01 -3.0555122e-02 -2.3477532e-01\n",
      " -1.6108487e-02 -6.2940526e-05 -7.8198238e-05 -1.4234318e-02\n",
      " -4.1540292e-01 -3.4464855e-02 -2.9294050e-01 -3.0805182e-02\n",
      " -2.9579505e-01 -9.0558842e-02 -2.3411827e-01 -9.0558842e-02\n",
      " -2.9579505e-01 -3.0805182e-02 -1.4208034e+00 -3.4464855e-02], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(11.542383, shape=(), dtype=float32)\n",
      "EPOCA: 0  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(11.542383, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[ 5.159771   -0.8714404  -4.55363    -4.1442957  -2.0813823   5.334819\n",
      "  4.6187716   3.7794394   0.11876488 -1.4134083  -3.5607285  -1.7755165\n",
      " -3.5607285  -1.4134083   0.11876488  3.7794394   4.6187716   5.334819\n",
      " -0.85342455 -4.1442957  -4.55363    -2.1602745   5.159771    4.330002\n",
      "  3.6987243   0.09413004 -1.5099182  -3.8181849  -1.7793708  -3.8181849\n",
      " -1.5099182   0.09413004  3.6987243   4.330002    5.159771   -0.8714404\n",
      " -4.55363    -4.1442957  -2.0813823   5.334819    4.6187716   3.7794394\n",
      "  0.11876488 -1.4134083  -3.5607285  -1.7755165  -3.5607285  -1.4134083\n",
      "  0.11876488  3.7794394   4.6187716   5.334819   -0.85342455 -4.1442957\n",
      " -4.55363    -2.1602745   5.159771    4.330002    3.6987243   0.09413004\n",
      " -1.5099182  -3.8181849  -1.7793708  -3.8181849 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[ 5.159771   -0.8714404  -4.55363    -4.1442957  -2.0813823   5.334819\n",
      "  4.6187716   3.7794394   0.11876488 -1.4134083  -3.5607285  -1.7755165\n",
      " -3.5607285  -1.4134083   0.11876488  3.7794394   4.6187716   5.334819\n",
      " -0.85342455 -4.1442957  -4.55363    -2.1602745   5.159771    4.330002\n",
      "  3.6987243   0.09413004 -1.5099182  -3.8181849  -1.7793708  -3.8181849\n",
      " -1.5099182   0.09413004  3.6987243   4.330002    5.159771   -0.8714404\n",
      " -4.55363    -4.1442957  -2.0813823   5.334819    4.6187716   3.7794394\n",
      "  0.11876488 -1.4134083  -3.5607285  -1.7755165  -3.5607285  -1.4134083\n",
      "  0.11876488  3.7794394   4.6187716   5.334819   -0.85342455 -4.1442957\n",
      " -4.55363    -2.1602745   5.159771    4.330002    3.6987243   0.09413004\n",
      " -1.5099182  -3.8181849  -1.7793708  -3.8181849 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-1.4579395   0.28250074  1.3450783   1.2269559   0.6316564  -1.5084535\n",
      " -1.3018221  -1.0596141  -0.00324501  0.43889764  1.0585546   0.543392\n",
      "  1.0585546   0.43889764 -0.00324501 -1.0596141  -1.3018221  -1.5084535\n",
      "  0.27730188  1.2269559   1.3450783   0.6544225  -1.4579395  -1.2184912\n",
      " -1.0363219   0.00386392  0.46674773  1.1328495   0.5445043   1.1328495\n",
      "  0.46674773  0.00386392 -1.0363219  -1.2184912  -1.4579395   0.28250074\n",
      "  1.3450783   1.2269559   0.6316564  -1.5084535  -1.3018221  -1.0596141\n",
      " -0.00324501  0.43889764  1.0585546   0.543392    1.0585546   0.43889764\n",
      " -0.00324501 -1.0596141  -1.3018221  -1.5084535   0.27730188  1.2269559\n",
      "  1.3450783   0.6544225  -1.4579395  -1.2184912  -1.0363219   0.00386392\n",
      "  0.46674773  1.1328495   0.5445043   1.1328495 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[-4.1540292e-01 -1.4015817e-02 -7.8198238e-05 -6.2940526e-05\n",
      " -1.8022703e-02 -2.3477532e-01 -3.0555122e-02 -2.8795019e-01\n",
      " -9.7555749e-02 -1.3108490e+00 -1.4359848e-01 -2.1838467e-01\n",
      " -1.4359848e-01 -3.1424010e-01 -9.7555749e-02 -2.8795019e-01\n",
      " -3.0555122e-02 -2.3477532e-01 -1.6108487e-02 -6.2940526e-05\n",
      " -7.8198238e-05 -1.4234318e-02 -1.0807242e+00 -3.4464855e-02\n",
      " -2.9294050e-01 -3.0805182e-02 -1.3625466e+00 -9.0558842e-02\n",
      " -2.3411827e-01 -9.0558842e-02 -1.3625466e+00 -3.0805182e-02\n",
      " -2.9294050e-01 -3.4464855e-02 -4.1540292e-01 -1.4015817e-02\n",
      " -7.8198238e-05 -6.2940526e-05 -1.8022703e-02 -2.3477532e-01\n",
      " -3.0555122e-02 -2.8795019e-01 -9.7555749e-02 -1.3108490e+00\n",
      " -1.4359848e-01 -2.1838467e-01 -1.4359848e-01 -3.1424010e-01\n",
      " -9.7555749e-02 -2.8795019e-01 -3.0555122e-02 -1.5662477e+00\n",
      " -1.6108487e-02 -6.2940526e-05 -7.8198238e-05 -1.4234318e-02\n",
      " -4.1540292e-01 -3.4464855e-02 -2.9294050e-01 -3.0805182e-02\n",
      " -2.9579505e-01 -9.0558842e-02 -2.3411827e-01 -9.0558842e-02], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(12.02012, shape=(), dtype=float32)\n",
      "EPOCA: 0  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(12.02012, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-1.5099182   0.09413004  3.6987243   4.330002    5.159771   -0.8714404\n",
      " -4.55363    -4.1442957  -2.0813823   5.334819    4.6187716   3.7794394\n",
      "  0.11876488 -1.4134083  -3.5607285  -1.7755165  -3.5607285  -1.4134083\n",
      "  0.11876488  3.7794394   4.6187716   5.334819   -0.85342455 -4.1442957\n",
      " -4.55363    -2.1602745   5.159771    4.330002    3.6987243   0.09413004\n",
      " -1.5099182  -3.8181849  -1.7793708  -3.8181849  -1.5099182   0.09413004\n",
      "  3.6987243   4.330002    5.159771   -0.8714404  -4.55363    -4.1442957\n",
      " -2.0813823   5.334819    4.6187716   3.7794394   0.11876488 -1.4134083\n",
      " -3.5607285  -1.7755165  -3.5607285  -1.4134083   0.11876488  3.7794394\n",
      "  4.6187716   5.334819   -0.85342455 -4.1442957  -4.55363    -2.1602745\n",
      "  5.159771    4.330002    3.6987243   0.09413004], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-1.5099182   0.09413004  3.6987243   4.330002    5.159771   -0.8714404\n",
      " -4.55363    -4.1442957  -2.0813823   5.334819    4.6187716   3.7794394\n",
      "  0.11876488 -1.4134083  -3.5607285  -1.7755165  -3.5607285  -1.4134083\n",
      "  0.11876488  3.7794394   4.6187716   5.334819   -0.85342455 -4.1442957\n",
      " -4.55363    -2.1602745   5.159771    4.330002    3.6987243   0.09413004\n",
      " -1.5099182  -3.8181849  -1.7793708  -3.8181849  -1.5099182   0.09413004\n",
      "  3.6987243   4.330002    5.159771   -0.8714404  -4.55363    -4.1442957\n",
      " -2.0813823   5.334819    4.6187716   3.7794394   0.11876488 -1.4134083\n",
      " -3.5607285  -1.7755165  -3.5607285  -1.4134083   0.11876488  3.7794394\n",
      "  4.6187716   5.334819   -0.85342455 -4.1442957  -4.55363    -2.1602745\n",
      "  5.159771    4.330002    3.6987243   0.09413004], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 0.5488584   0.08340489 -0.9625556  -1.1457361  -1.3865137   0.3635886\n",
      "  1.4320651   1.3132869   0.7146825  -1.4373081  -1.2295296  -0.98597705\n",
      "  0.0762565   0.5208537   1.1439507   0.62592816  1.1439507   0.5208537\n",
      "  0.0762565  -0.98597705 -1.2295296  -1.4373081   0.35836086  1.3132869\n",
      "  1.4320651   0.737575   -1.3865137  -1.1457361  -0.9625556   0.08340489\n",
      "  0.5488584   1.218658    0.6270466   1.218658    0.5488584   0.08340489\n",
      " -0.9625556  -1.1457361  -1.3865137   0.3635886   1.4320651   1.3132869\n",
      "  0.7146825  -1.4373081  -1.2295296  -0.98597705  0.0762565   0.5208537\n",
      "  1.1439507   0.62592816  1.1439507   0.5208537   0.0762565  -0.98597705\n",
      " -1.2295296  -1.4373081   0.35836086  1.3132869   1.4320651   0.737575\n",
      " -1.3865137  -1.1457361  -0.9625556   0.08340489], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[-2.9579505e-01 -3.0805182e-02 -2.9294050e-01 -3.4464855e-02\n",
      " -4.1540292e-01 -1.4015817e-02 -7.8198238e-05 -6.2940526e-05\n",
      " -1.8022703e-02 -1.5662477e+00 -3.0555122e-02 -1.4326073e+00\n",
      " -2.3792901e+00 -3.1424010e-01 -1.4359848e-01 -2.1838467e-01\n",
      " -1.4359848e-01 -1.3108490e+00 -9.7555749e-02 -1.4326073e+00\n",
      " -3.0555122e-02 -2.3477532e-01 -4.1414671e+00 -6.2940526e-05\n",
      " -7.8198238e-05 -1.4234318e-02 -4.1540292e-01 -3.4464855e-02\n",
      " -2.9294050e-01 -3.0805182e-02 -2.9579505e-01 -9.0558842e-02\n",
      " -2.3411827e-01 -9.0558842e-02 -2.9579505e-01 -3.0805182e-02\n",
      " -2.9294050e-01 -3.4464855e-02 -1.0807242e+00 -1.4015817e-02\n",
      " -7.8198238e-05 -6.2940526e-05 -1.8022703e-02 -2.3477532e-01\n",
      " -3.0555122e-02 -1.4326073e+00 -9.7555749e-02 -3.1424010e-01\n",
      " -1.4359848e-01 -1.6294907e+00 -1.4359848e-01 -3.1424010e-01\n",
      " -9.7555749e-02 -1.4326073e+00 -3.0555122e-02 -2.3477532e-01\n",
      " -1.6108487e-02 -6.2940526e-05 -7.8198238e-05 -1.4234318e-02\n",
      " -1.0807242e+00 -3.4464855e-02 -2.9294050e-01 -3.0805182e-02], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(12.021918, shape=(), dtype=float32)\n",
      "EPOCA: 0  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(12.021918, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-1.5099182  -3.8181849  -1.7793708  -3.8181849  -1.5099182   0.09413004\n",
      "  3.6987243   4.330002    5.159771   -0.8714404  -4.55363    -4.1442957\n",
      " -2.0813823   5.334819    4.6187716   3.7794394   0.11876488 -1.4134083\n",
      " -3.5607285  -1.7755165  -3.5607285  -1.4134083   0.11876488  3.7794394\n",
      "  4.6187716   5.334819   -0.85342455 -4.1442957  -4.55363    -2.1602745\n",
      "  5.159771    4.330002    3.6987243   0.09413004 -1.5099182  -3.8181849\n",
      " -1.7793708  -3.8181849  -1.5099182   0.09413004  3.6987243   4.330002\n",
      "  5.159771   -0.8714404  -4.55363    -4.1442957  -2.0813823   5.334819\n",
      "  4.6187716   3.7794394   0.11876488 -1.4134083  -3.5607285  -1.7755165\n",
      " -3.5607285  -1.4134083   0.11876488  3.7794394   4.6187716   5.334819\n",
      " -0.85342455 -4.1442957  -4.55363    -2.1602745 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-1.5099182  -3.8181849  -1.7793708  -3.8181849  -1.5099182   0.09413004\n",
      "  3.6987243   4.330002    5.159771   -0.8714404  -4.55363    -4.1442957\n",
      " -2.0813823   5.334819    4.6187716   3.7794394   0.11876488 -1.4134083\n",
      " -3.5607285  -1.7755165  -3.5607285  -1.4134083   0.11876488  3.7794394\n",
      "  4.6187716   5.334819   -0.85342455 -4.1442957  -4.55363    -2.1602745\n",
      "  5.159771    4.330002    3.6987243   0.09413004 -1.5099182  -3.8181849\n",
      " -1.7793708  -3.8181849  -1.5099182   0.09413004  3.6987243   4.330002\n",
      "  5.159771   -0.8714404  -4.55363    -4.1442957  -2.0813823   5.334819\n",
      "  4.6187716   3.7794394   0.11876488 -1.4134083  -3.5607285  -1.7755165\n",
      " -3.5607285  -1.4134083   0.11876488  3.7794394   4.6187716   5.334819\n",
      " -0.85342455 -4.1442957  -4.55363    -2.1602745 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 0.44353876  1.1201112   0.52251756  1.1201112   0.44353876 -0.02662131\n",
      " -1.0831583  -1.2681911  -1.5114034   0.25639555  1.3356763   1.215697\n",
      "  0.6110397  -1.5627114  -1.352832   -1.1068165  -0.03384199  0.41525087\n",
      "  1.0446485   0.5213879   1.0446485   0.41525087 -0.03384199 -1.1068165\n",
      " -1.352832   -1.5627114   0.25111493  1.215697    1.3356763   0.6341637\n",
      " -1.5114034  -1.2681911  -1.0831583  -0.02662131  0.44353876  1.1201112\n",
      "  0.52251756  1.1201112   0.44353876 -0.02662131 -1.0831583  -1.2681911\n",
      " -1.5114034   0.25639555  1.3356763   1.215697    0.6110397  -1.5627114\n",
      " -1.352832   -1.1068165  -0.03384199  0.41525087  1.0446485   0.5213879\n",
      "  1.0446485   0.41525087 -0.03384199 -1.1068165  -1.352832   -1.5627114\n",
      "  0.25111493  1.215697    1.3356763   0.6341637 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[-2.9579505e-01 -2.4489231e+00 -2.3411827e-01 -9.0558842e-02\n",
      " -2.9579505e-01 -3.0805182e-02 -1.4208034e+00 -3.4464855e-02\n",
      " -4.1540292e-01 -1.4015817e-02 -7.8198238e-05 -6.2940526e-05\n",
      " -1.8022703e-02 -2.3477532e-01 -3.0555122e-02 -2.8795019e-01\n",
      " -9.7555749e-02 -3.1424010e-01 -1.4359848e-01 -2.1838467e-01\n",
      " -1.4359848e-01 -3.1424010e-01 -9.7555749e-02 -1.4326073e+00\n",
      " -3.0555122e-02 -2.3477532e-01 -1.6108487e-02 -6.2940526e-05\n",
      " -7.8198238e-05 -1.4234318e-02 -4.1540292e-01 -3.4464855e-02\n",
      " -2.9294050e-01 -3.0805182e-02 -2.9579505e-01 -9.0558842e-02\n",
      " -2.3411827e-01 -9.0558842e-02 -2.9579505e-01 -3.0805182e-02\n",
      " -2.9294050e-01 -3.4464855e-02 -4.1540292e-01 -1.4015817e-02\n",
      " -7.8198238e-05 -6.2940526e-05 -1.8022703e-02 -2.3477532e-01\n",
      " -3.0555122e-02 -2.8795019e-01 -9.7555749e-02 -1.3108490e+00\n",
      " -1.4359848e-01 -2.1838467e-01 -1.4359848e-01 -3.1424010e-01\n",
      " -9.7555749e-02 -2.8795019e-01 -5.1421905e+00 -1.5662477e+00\n",
      " -1.6108487e-02 -6.2940526e-05 -7.8198238e-05 -1.4234318e-02], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(11.639754, shape=(), dtype=float32)\n",
      "EPOCA: 0  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(11.639754, shape=(), dtype=float32)\n",
      "Warning: early reset ignored\n",
      "Episode:  0\n",
      "CALC REWARDS TO GO\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "BATCH LOG PROBS: [<tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>]\n",
      "Trajectories collected\n",
      "V EVALUATE: tf.Tensor(\n",
      "[ 5.159771    4.9888916   4.3416147   1.4038749  -0.68009615 -2.6123753\n",
      " -0.46451283 -2.6123753  -0.1773231   1.5816185   4.222424    4.9327106\n",
      "  5.3829384  -1.6372957  -4.7954354  -4.3829856  -5.6534014  -5.261038\n",
      " -4.7954354  -4.3829856  -4.7954354  -4.3829856  -4.7954354  -5.261038\n",
      " -5.6534014  -5.261038   -5.6534014  -5.261038   -4.7954354  -4.3829856\n",
      " -4.7954354  -4.3829856  -4.7954354  -5.261038   -5.6534014  -5.261038\n",
      " -5.6534014  -5.261038   -4.7954354  -4.3829856  -4.7954354  -4.3829856\n",
      " -4.7954354  -5.261038   -5.6534014  -5.261038   -5.6534014  -5.261038\n",
      " -4.7954354  -4.3829856  -4.7954354  -4.3829856  -4.7954354  -5.261038\n",
      " -5.6534014  -5.261038   -5.6534014  -5.261038   -4.7954354  -4.3829856\n",
      " -4.7954354  -4.3829856  -4.7954354  -5.261038  ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[ 5.159771    4.9888916   4.3416147   1.4038749  -0.68009615 -2.6123753\n",
      " -0.46451283 -2.6123753  -0.1773231   1.5816185   4.222424    4.9327106\n",
      "  5.3829384  -1.6372957  -4.7954354  -4.3829856  -5.6534014  -5.261038\n",
      " -4.7954354  -4.3829856  -4.7954354  -4.3829856  -4.7954354  -5.261038\n",
      " -5.6534014  -5.261038   -5.6534014  -5.261038   -4.7954354  -4.3829856\n",
      " -4.7954354  -4.3829856  -4.7954354  -5.261038   -5.6534014  -5.261038\n",
      " -5.6534014  -5.261038   -4.7954354  -4.3829856  -4.7954354  -4.3829856\n",
      " -4.7954354  -5.261038   -5.6534014  -5.261038   -5.6534014  -5.261038\n",
      " -4.7954354  -4.3829856  -4.7954354  -4.3829856  -4.7954354  -5.261038\n",
      " -5.6534014  -5.261038   -5.6534014  -5.261038   -4.7954354  -4.3829856\n",
      " -4.7954354  -4.3829856  -4.7954354  -5.261038  ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-2.78637    -2.7315507  -2.523899   -1.5814486  -0.91289395 -0.2930033\n",
      " -0.98205477 -0.2930033  -1.0741875  -1.63847    -2.4856617  -2.7135274\n",
      " -2.857964   -0.60581666  0.4073399   0.2750227   0.68258226  0.5567089\n",
      "  0.4073399   0.2750227   0.4073399   0.2750227   0.4073399   0.5567089\n",
      "  0.68258226  0.5567089   0.68258226  0.5567089   0.4073399   0.2750227\n",
      "  0.4073399   0.2750227   0.4073399   0.5567089   0.68258226  0.5567089\n",
      "  0.68258226  0.5567089   0.4073399   0.2750227   0.4073399   0.2750227\n",
      "  0.4073399   0.5567089   0.68258226  0.5567089   0.68258226  0.5567089\n",
      "  0.4073399   0.2750227   0.4073399   0.2750227   0.4073399   0.5567089\n",
      "  0.68258226  0.5567089   0.68258226  0.5567089   0.4073399   0.2750227\n",
      "  0.4073399   0.2750227   0.4073399   0.5567089 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(22.147085, shape=(), dtype=float32)\n",
      "EPOCA: 1  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(22.147085, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "EPOCA: 1  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "EPOCA: 1  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "EPOCA: 1  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "EPOCA: 1  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "EPOCA: 1  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "EPOCA: 1  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373 -4.795452  -4.3829975\n",
      " -4.795452  -4.3829975 -4.795452  -5.2610373 -5.653403  -5.2610373\n",
      " -5.653403  -5.2610373 -4.795452  -4.3829975 -4.795452  -4.3829975\n",
      " -4.795452  -5.2610373 -5.653403  -5.2610373 -5.653403  -5.2610373\n",
      " -4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373], shape=(40,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(40, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373 -4.795452  -4.3829975\n",
      " -4.795452  -4.3829975 -4.795452  -5.2610373 -5.653403  -5.2610373\n",
      " -5.653403  -5.2610373 -4.795452  -4.3829975 -4.795452  -4.3829975\n",
      " -4.795452  -5.2610373 -5.653403  -5.2610373 -5.653403  -5.2610373\n",
      " -4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373], shape=(40,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(40, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.51949716 -1.4560899  -0.51949716 -1.4560899  -0.51949716  0.5377433\n",
      "  1.428718    0.5377433   1.428718    0.5377433  -0.51949716 -1.4560899\n",
      " -0.51949716 -1.4560899  -0.51949716  0.5377433   1.428718    0.5377433\n",
      "  1.428718    0.5377433  -0.51949716 -1.4560899  -0.51949716 -1.4560899\n",
      " -0.51949716  0.5377433   1.428718    0.5377433   1.428718    0.5377433\n",
      " -0.51949716 -1.4560899  -0.51949716 -1.4560899  -0.51949716  0.5377433\n",
      "  1.428718    0.5377433   1.428718    0.5377433 ], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.436789, shape=(), dtype=float32)\n",
      "EPOCA: 1  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.436789, shape=(), dtype=float32)\n",
      "Episode:  0\n",
      "CALC REWARDS TO GO\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "BATCH LOG PROBS: [<tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>]\n",
      "Trajectories collected\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.55363   -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.55363   -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.98801714 -1.371526   -0.44457915 -1.371526   -0.44457915  0.60182375\n",
      "  1.4836284   0.60182375  1.4836284   0.60182375 -0.44457915 -1.371526\n",
      " -0.44457915 -1.371526   -0.44457915  0.60182375  1.4836284   0.60182375\n",
      "  1.4836284   0.60182375 -0.44457915 -1.371526   -0.44457915 -1.371526\n",
      " -0.44457915  0.60182375  1.4836284   0.60182375  1.4836284   0.60182375\n",
      " -0.44457915 -1.371526   -0.44457915 -1.371526   -0.44457915  0.60182375\n",
      "  1.4836284   0.60182375  1.4836284   0.60182375 -0.44457915 -1.371526\n",
      " -0.44457915 -1.371526   -0.44457915  0.60182375  1.4836284   0.60182375\n",
      "  1.4836284   0.60182375 -0.44457915 -1.371526   -0.44457915 -1.371526\n",
      " -0.44457915  0.60182375  1.4836284   0.60182375  1.4836284   0.60182375\n",
      " -0.44457915 -1.371526   -0.44457915 -1.371526  ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.130562, shape=(), dtype=float32)\n",
      "EPOCA: 2  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.130562, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "EPOCA: 2  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "EPOCA: 2  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "EPOCA: 2  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "EPOCA: 2  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "EPOCA: 2  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "EPOCA: 2  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "EPOCA: 2  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "Warning: early reset ignored\n",
      "Episode:  0\n",
      "CALC REWARDS TO GO\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "BATCH LOG PROBS: [<tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>]\n",
      "Trajectories collected\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "EPOCA: 3  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "EPOCA: 3  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "EPOCA: 3  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "EPOCA: 3  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "EPOCA: 3  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "EPOCA: 3  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "EPOCA: 3  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373 -4.795452  -4.3829975\n",
      " -4.795452  -4.3829975 -4.795452  -5.2610373 -5.653403  -5.2610373\n",
      " -5.653403  -5.2610373 -4.795452  -4.3829975 -4.795452  -4.3829975\n",
      " -4.795452  -5.2610373 -5.653403  -5.2610373 -5.653403  -5.2610373\n",
      " -4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373], shape=(40,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(40, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373 -4.795452  -4.3829975\n",
      " -4.795452  -4.3829975 -4.795452  -5.2610373 -5.653403  -5.2610373\n",
      " -5.653403  -5.2610373 -4.795452  -4.3829975 -4.795452  -4.3829975\n",
      " -4.795452  -5.2610373 -5.653403  -5.2610373 -5.653403  -5.2610373\n",
      " -4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373], shape=(40,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(40, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.51949716 -1.4560899  -0.51949716 -1.4560899  -0.51949716  0.5377433\n",
      "  1.428718    0.5377433   1.428718    0.5377433  -0.51949716 -1.4560899\n",
      " -0.51949716 -1.4560899  -0.51949716  0.5377433   1.428718    0.5377433\n",
      "  1.428718    0.5377433  -0.51949716 -1.4560899  -0.51949716 -1.4560899\n",
      " -0.51949716  0.5377433   1.428718    0.5377433   1.428718    0.5377433\n",
      " -0.51949716 -1.4560899  -0.51949716 -1.4560899  -0.51949716  0.5377433\n",
      "  1.428718    0.5377433   1.428718    0.5377433 ], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.436789, shape=(), dtype=float32)\n",
      "EPOCA: 3  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.436789, shape=(), dtype=float32)\n",
      "Episode:  0\n",
      "CALC REWARDS TO GO\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "BATCH LOG PROBS: [<tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>]\n",
      "Trajectories collected\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.55363   -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.55363   -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.98801714 -1.371526   -0.44457915 -1.371526   -0.44457915  0.60182375\n",
      "  1.4836284   0.60182375  1.4836284   0.60182375 -0.44457915 -1.371526\n",
      " -0.44457915 -1.371526   -0.44457915  0.60182375  1.4836284   0.60182375\n",
      "  1.4836284   0.60182375 -0.44457915 -1.371526   -0.44457915 -1.371526\n",
      " -0.44457915  0.60182375  1.4836284   0.60182375  1.4836284   0.60182375\n",
      " -0.44457915 -1.371526   -0.44457915 -1.371526   -0.44457915  0.60182375\n",
      "  1.4836284   0.60182375  1.4836284   0.60182375 -0.44457915 -1.371526\n",
      " -0.44457915 -1.371526   -0.44457915  0.60182375  1.4836284   0.60182375\n",
      "  1.4836284   0.60182375 -0.44457915 -1.371526   -0.44457915 -1.371526\n",
      " -0.44457915  0.60182375  1.4836284   0.60182375  1.4836284   0.60182375\n",
      " -0.44457915 -1.371526   -0.44457915 -1.371526  ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.130562, shape=(), dtype=float32)\n",
      "EPOCA: 4  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.130562, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "EPOCA: 4  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "EPOCA: 4  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "EPOCA: 4  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "EPOCA: 4  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "EPOCA: 4  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "EPOCA: 4  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "EPOCA: 4  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "Warning: early reset ignored\n",
      "Episode:  0\n",
      "CALC REWARDS TO GO\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "BATCH LOG PROBS: [<tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>]\n",
      "Trajectories collected\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "EPOCA: 5  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "EPOCA: 5  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "EPOCA: 5  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "EPOCA: 5  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "EPOCA: 5  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "EPOCA: 5  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "EPOCA: 5  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373 -4.795452  -4.3829975\n",
      " -4.795452  -4.3829975 -4.795452  -5.2610373 -5.653403  -5.2610373\n",
      " -5.653403  -5.2610373 -4.795452  -4.3829975 -4.795452  -4.3829975\n",
      " -4.795452  -5.2610373 -5.653403  -5.2610373 -5.653403  -5.2610373\n",
      " -4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373], shape=(40,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(40, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373 -4.795452  -4.3829975\n",
      " -4.795452  -4.3829975 -4.795452  -5.2610373 -5.653403  -5.2610373\n",
      " -5.653403  -5.2610373 -4.795452  -4.3829975 -4.795452  -4.3829975\n",
      " -4.795452  -5.2610373 -5.653403  -5.2610373 -5.653403  -5.2610373\n",
      " -4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373], shape=(40,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(40, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.51949716 -1.4560899  -0.51949716 -1.4560899  -0.51949716  0.5377433\n",
      "  1.428718    0.5377433   1.428718    0.5377433  -0.51949716 -1.4560899\n",
      " -0.51949716 -1.4560899  -0.51949716  0.5377433   1.428718    0.5377433\n",
      "  1.428718    0.5377433  -0.51949716 -1.4560899  -0.51949716 -1.4560899\n",
      " -0.51949716  0.5377433   1.428718    0.5377433   1.428718    0.5377433\n",
      " -0.51949716 -1.4560899  -0.51949716 -1.4560899  -0.51949716  0.5377433\n",
      "  1.428718    0.5377433   1.428718    0.5377433 ], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.436789, shape=(), dtype=float32)\n",
      "EPOCA: 5  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.436789, shape=(), dtype=float32)\n",
      "Episode:  0\n",
      "CALC REWARDS TO GO\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "BATCH LOG PROBS: [<tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>]\n",
      "Trajectories collected\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.55363   -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.55363   -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.98801714 -1.371526   -0.44457915 -1.371526   -0.44457915  0.60182375\n",
      "  1.4836284   0.60182375  1.4836284   0.60182375 -0.44457915 -1.371526\n",
      " -0.44457915 -1.371526   -0.44457915  0.60182375  1.4836284   0.60182375\n",
      "  1.4836284   0.60182375 -0.44457915 -1.371526   -0.44457915 -1.371526\n",
      " -0.44457915  0.60182375  1.4836284   0.60182375  1.4836284   0.60182375\n",
      " -0.44457915 -1.371526   -0.44457915 -1.371526   -0.44457915  0.60182375\n",
      "  1.4836284   0.60182375  1.4836284   0.60182375 -0.44457915 -1.371526\n",
      " -0.44457915 -1.371526   -0.44457915  0.60182375  1.4836284   0.60182375\n",
      "  1.4836284   0.60182375 -0.44457915 -1.371526   -0.44457915 -1.371526\n",
      " -0.44457915  0.60182375  1.4836284   0.60182375  1.4836284   0.60182375\n",
      " -0.44457915 -1.371526   -0.44457915 -1.371526  ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.130562, shape=(), dtype=float32)\n",
      "EPOCA: 6  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.130562, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "EPOCA: 6  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "EPOCA: 6  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "EPOCA: 6  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "EPOCA: 6  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "EPOCA: 6  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "EPOCA: 6  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "EPOCA: 6  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "Warning: early reset ignored\n",
      "Episode:  0\n",
      "CALC REWARDS TO GO\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "BATCH LOG PROBS: [<tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>]\n",
      "Trajectories collected\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "EPOCA: 7  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "EPOCA: 7  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "EPOCA: 7  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "EPOCA: 7  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "EPOCA: 7  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "EPOCA: 7  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "EPOCA: 7  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373 -4.795452  -4.3829975\n",
      " -4.795452  -4.3829975 -4.795452  -5.2610373 -5.653403  -5.2610373\n",
      " -5.653403  -5.2610373 -4.795452  -4.3829975 -4.795452  -4.3829975\n",
      " -4.795452  -5.2610373 -5.653403  -5.2610373 -5.653403  -5.2610373\n",
      " -4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373], shape=(40,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(40, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373 -4.795452  -4.3829975\n",
      " -4.795452  -4.3829975 -4.795452  -5.2610373 -5.653403  -5.2610373\n",
      " -5.653403  -5.2610373 -4.795452  -4.3829975 -4.795452  -4.3829975\n",
      " -4.795452  -5.2610373 -5.653403  -5.2610373 -5.653403  -5.2610373\n",
      " -4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373], shape=(40,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(40, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.51949716 -1.4560899  -0.51949716 -1.4560899  -0.51949716  0.5377433\n",
      "  1.428718    0.5377433   1.428718    0.5377433  -0.51949716 -1.4560899\n",
      " -0.51949716 -1.4560899  -0.51949716  0.5377433   1.428718    0.5377433\n",
      "  1.428718    0.5377433  -0.51949716 -1.4560899  -0.51949716 -1.4560899\n",
      " -0.51949716  0.5377433   1.428718    0.5377433   1.428718    0.5377433\n",
      " -0.51949716 -1.4560899  -0.51949716 -1.4560899  -0.51949716  0.5377433\n",
      "  1.428718    0.5377433   1.428718    0.5377433 ], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.436789, shape=(), dtype=float32)\n",
      "EPOCA: 7  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.436789, shape=(), dtype=float32)\n",
      "Episode:  0\n",
      "CALC REWARDS TO GO\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "BATCH LOG PROBS: [<tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>]\n",
      "Trajectories collected\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.55363   -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.55363   -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.98801714 -1.371526   -0.44457915 -1.371526   -0.44457915  0.60182375\n",
      "  1.4836284   0.60182375  1.4836284   0.60182375 -0.44457915 -1.371526\n",
      " -0.44457915 -1.371526   -0.44457915  0.60182375  1.4836284   0.60182375\n",
      "  1.4836284   0.60182375 -0.44457915 -1.371526   -0.44457915 -1.371526\n",
      " -0.44457915  0.60182375  1.4836284   0.60182375  1.4836284   0.60182375\n",
      " -0.44457915 -1.371526   -0.44457915 -1.371526   -0.44457915  0.60182375\n",
      "  1.4836284   0.60182375  1.4836284   0.60182375 -0.44457915 -1.371526\n",
      " -0.44457915 -1.371526   -0.44457915  0.60182375  1.4836284   0.60182375\n",
      "  1.4836284   0.60182375 -0.44457915 -1.371526   -0.44457915 -1.371526\n",
      " -0.44457915  0.60182375  1.4836284   0.60182375  1.4836284   0.60182375\n",
      " -0.44457915 -1.371526   -0.44457915 -1.371526  ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.130562, shape=(), dtype=float32)\n",
      "EPOCA: 8  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.130562, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "EPOCA: 8  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "EPOCA: 8  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "EPOCA: 8  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "EPOCA: 8  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "EPOCA: 8  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "EPOCA: 8  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "EPOCA: 8  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "Warning: early reset ignored\n",
      "Episode:  0\n",
      "CALC REWARDS TO GO\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "BATCH LOG PROBS: [<tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>, <tf.Tensor: shape=(), dtype=float32, numpy=nan>]\n",
      "Trajectories collected\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "EPOCA: 9  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "EPOCA: 9  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384  -0.45586756  0.5969969\n",
      "  1.4842467   0.5969969   1.4842467   0.5969969  -0.45586756 -1.3885384\n",
      " -0.45586756 -1.3885384  -0.45586756  0.5969969   1.4842467   0.5969969\n",
      "  1.4842467   0.5969969  -0.45586756 -1.3885384  -0.45586756 -1.3885384\n",
      " -0.45586756  0.5969969   1.4842467   0.5969969   1.4842467   0.5969969\n",
      " -0.45586756 -1.3885384  -0.45586756 -1.3885384 ], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "EPOCA: 9  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.165886, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886  1.4106797   0.51144886\n",
      " -0.55563307 -1.5008984  -0.55563307 -1.5008984  -0.55563307  0.51144886\n",
      "  1.4106797   0.51144886  1.4106797   0.51144886 -0.55563307 -1.5008984\n",
      " -0.55563307 -1.5008984  -0.55563307  0.51144886  1.4106797   0.51144886\n",
      "  1.4106797   0.51144886 -0.55563307 -1.5008984  -0.55563307 -1.5008984\n",
      " -0.55563307  0.51144886  1.4106797   0.51144886], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "EPOCA: 9  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.570581, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112 -0.5164692 -1.4478112\n",
      " -0.5164692  0.5348953  1.420881   0.5348953  1.420881   0.5348953\n",
      " -0.5164692 -1.4478112 -0.5164692 -1.4478112 -0.5164692  0.5348953\n",
      "  1.420881   0.5348953  1.420881   0.5348953 -0.5164692 -1.4478112\n",
      " -0.5164692 -1.4478112 -0.5164692  0.5348953  1.420881   0.5348953\n",
      "  1.420881   0.5348953 -0.5164692 -1.4478112], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "EPOCA: 9  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.43827, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577  1.4721279   0.57333577\n",
      "  1.4721279   0.57333577 -0.4932256  -1.4380298  -0.4932256  -1.4380298\n",
      " -0.4932256   0.57333577  1.4721279   0.57333577  1.4721279   0.57333577\n",
      " -0.4932256  -1.4380298  -0.4932256  -1.4380298  -0.4932256   0.57333577\n",
      "  1.4721279   0.57333577  1.4721279   0.57333577 -0.4932256  -1.4380298\n",
      " -0.4932256  -1.4380298  -0.4932256   0.57333577], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "EPOCA: 9  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.298195, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038  -4.7954354 -4.3829856\n",
      " -4.7954354 -4.3829856 -4.7954354 -5.261038  -5.6534014 -5.261038\n",
      " -5.6534014 -5.261038  -4.7954354 -4.3829856 -4.7954354 -4.3829856\n",
      " -4.7954354 -5.261038  -5.6534014 -5.261038  -5.6534014 -5.261038\n",
      " -4.7954354 -4.3829856 -4.7954354 -4.3829856 -4.7954354 -5.261038\n",
      " -5.6534014 -5.261038  -5.6534014 -5.261038 ], shape=(64,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(64, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[ 1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076 -0.5790699  -1.5125878\n",
      " -0.5790699  -1.5125878  -0.5790699   0.47475076  1.3628063   0.47475076\n",
      "  1.3628063   0.47475076 -0.5790699  -1.5125878  -0.5790699  -1.5125878\n",
      " -0.5790699   0.47475076  1.3628063   0.47475076  1.3628063   0.47475076\n",
      " -0.5790699  -1.5125878  -0.5790699  -1.5125878  -0.5790699   0.47475076\n",
      "  1.3628063   0.47475076  1.3628063   0.47475076], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan], shape=(64,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "EPOCA: 9  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.710655, shape=(), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373 -4.795452  -4.3829975\n",
      " -4.795452  -4.3829975 -4.795452  -5.2610373 -5.653403  -5.2610373\n",
      " -5.653403  -5.2610373 -4.795452  -4.3829975 -4.795452  -4.3829975\n",
      " -4.795452  -5.2610373 -5.653403  -5.2610373 -5.653403  -5.2610373\n",
      " -4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373], shape=(40,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(40, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "V EVALUATE: tf.Tensor(\n",
      "[-4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373 -4.795452  -4.3829975\n",
      " -4.795452  -4.3829975 -4.795452  -5.2610373 -5.653403  -5.2610373\n",
      " -5.653403  -5.2610373 -4.795452  -4.3829975 -4.795452  -4.3829975\n",
      " -4.795452  -5.2610373 -5.653403  -5.2610373 -5.653403  -5.2610373\n",
      " -4.795452  -4.3829975 -4.795452  -4.3829975 -4.795452  -5.2610373\n",
      " -5.653403  -5.2610373 -5.653403  -5.2610373], shape=(40,), dtype=float32)\n",
      "MEAN EVALUATE: tf.Tensor(\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]], shape=(40, 15), dtype=float32)\n",
      "LOG PROBS EVALUATE: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, ADVANTAGES: tf.Tensor(\n",
      "[-0.51949716 -1.4560899  -0.51949716 -1.4560899  -0.51949716  0.5377433\n",
      "  1.428718    0.5377433   1.428718    0.5377433  -0.51949716 -1.4560899\n",
      " -0.51949716 -1.4560899  -0.51949716  0.5377433   1.428718    0.5377433\n",
      "  1.428718    0.5377433  -0.51949716 -1.4560899  -0.51949716 -1.4560899\n",
      " -0.51949716  0.5377433   1.428718    0.5377433   1.428718    0.5377433\n",
      " -0.51949716 -1.4560899  -0.51949716 -1.4560899  -0.51949716  0.5377433\n",
      "  1.428718    0.5377433   1.428718    0.5377433 ], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs old: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Log probs new: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "CALC SURROGATED LOSS, Policy ratio : tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Surrogated Loss 1: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Surrogated Loss 2: tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan], shape=(40,), dtype=float32)\n",
      "Policy Loss: tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Value Loss: tf.Tensor(25.436789, shape=(), dtype=float32)\n",
      "EPOCA: 9  POLICY LOSS: tf.Tensor(nan, shape=(), dtype=float32)  VALUE LOSS: tf.Tensor(25.436789, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Configurazione ed esecuzione\n",
    "env = gym.make('procgen:procgen-coinrun-v0',distribution_mode='easy', start_level=0, num_levels=1)\n",
    "ppo_model=PPO()\n",
    "ppo_model.learn(env)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
